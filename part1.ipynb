{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a8ca3d4",
   "metadata": {},
   "source": [
    "# Tests extracción de rasgos estilométricos con RAID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93ca329b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import math\n",
    "# import random\n",
    "# import matplotlib.pyplot as plt\n",
    "# import cvxopt\n",
    "# import seaborn as sns\n",
    "# import soundfile as sf\n",
    "# import itertools\n",
    "# import pywt\n",
    "# import librosa\n",
    "# import librosa.display\n",
    "# from IPython.display import Audio\n",
    "# from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "# from cvxopt import matrix, solvers\n",
    "# import pandas as pd\n",
    "# import os\n",
    "# import scipy\n",
    "# import scipy.signal\n",
    "# from sklearn.decomposition import PCA, TruncatedSVD, FactorAnalysis\n",
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.random_projection import SparseRandomProjection, johnson_lindenstrauss_min_dim, GaussianRandomProjection\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# import torch\n",
    "# from torch import nn\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed67f409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stylo_metrix as sm\n",
    "import pandas as pd\n",
    "from raid import run_detection, run_evaluation\n",
    "from raid.utils import load_data\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "from processer import split_text_into_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8500ce",
   "metadata": {},
   "source": [
    "## Manejo de RAID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "566ccaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the RAID dataset without adversarial attacks\n",
    "or_train_noadv_df = load_data(split=\"train\", include_adversarial=False)\n",
    "# test_noadv_df = load_data(split=\"test\", include_adversarial=False)\n",
    "# extra_noadv_df = load_data(split=\"extra\", include_adversarial=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fb4873d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>adv_source_id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>model</th>\n",
       "      <th>decoding</th>\n",
       "      <th>repetition_penalty</th>\n",
       "      <th>attack</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>prompt</th>\n",
       "      <th>generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e5e058ce-be2b-459d-af36-32532aaba5ff</td>\n",
       "      <td>e5e058ce-be2b-459d-af36-32532aaba5ff</td>\n",
       "      <td>e5e058ce-be2b-459d-af36-32532aaba5ff</td>\n",
       "      <td>human</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The recent advancements in artificial intellig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f95b107b-d176-4af5-90f7-4d0bb20caf93</td>\n",
       "      <td>f95b107b-d176-4af5-90f7-4d0bb20caf93</td>\n",
       "      <td>f95b107b-d176-4af5-90f7-4d0bb20caf93</td>\n",
       "      <td>human</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>EdgeFlow: Achieving Practical Interactive Segm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High-quality training data play a key role in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>856d8972-9e3d-4544-babc-0fe16f21e04d</td>\n",
       "      <td>856d8972-9e3d-4544-babc-0fe16f21e04d</td>\n",
       "      <td>856d8972-9e3d-4544-babc-0fe16f21e04d</td>\n",
       "      <td>human</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Semi-supervised Contrastive Learning for Label...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The success of deep learning methods in medica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fbc8a5ea-90fa-47b8-8fa7-73dd954f1524</td>\n",
       "      <td>fbc8a5ea-90fa-47b8-8fa7-73dd954f1524</td>\n",
       "      <td>fbc8a5ea-90fa-47b8-8fa7-73dd954f1524</td>\n",
       "      <td>human</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Combo Loss: Handling Input and Output Imbalanc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Simultaneous segmentation of multiple organs f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72c41b8d-0069-4886-b734-a4000ffca286</td>\n",
       "      <td>72c41b8d-0069-4886-b734-a4000ffca286</td>\n",
       "      <td>72c41b8d-0069-4886-b734-a4000ffca286</td>\n",
       "      <td>human</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Attention-Based 3D Seismic Fault Segmentation ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Detection faults in seismic data is a crucial ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>72fe360b-cce6-4daf-b66a-1d778f5964f8</td>\n",
       "      <td>72fe360b-cce6-4daf-b66a-1d778f5964f8</td>\n",
       "      <td>72fe360b-cce6-4daf-b66a-1d778f5964f8</td>\n",
       "      <td>human</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Segmenter: Transformer for Semantic Segmentation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Image segmentation is often ambiguous at the l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>df594cf4-9a0c-4488-bcb3-68f41e2d5a16</td>\n",
       "      <td>df594cf4-9a0c-4488-bcb3-68f41e2d5a16</td>\n",
       "      <td>df594cf4-9a0c-4488-bcb3-68f41e2d5a16</td>\n",
       "      <td>human</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Mining Contextual Information Beyond Image for...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This paper studies the context aggregation pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id                         adv_source_id  \\\n",
       "0  e5e058ce-be2b-459d-af36-32532aaba5ff  e5e058ce-be2b-459d-af36-32532aaba5ff   \n",
       "1  f95b107b-d176-4af5-90f7-4d0bb20caf93  f95b107b-d176-4af5-90f7-4d0bb20caf93   \n",
       "2  856d8972-9e3d-4544-babc-0fe16f21e04d  856d8972-9e3d-4544-babc-0fe16f21e04d   \n",
       "3  fbc8a5ea-90fa-47b8-8fa7-73dd954f1524  fbc8a5ea-90fa-47b8-8fa7-73dd954f1524   \n",
       "4  72c41b8d-0069-4886-b734-a4000ffca286  72c41b8d-0069-4886-b734-a4000ffca286   \n",
       "5  72fe360b-cce6-4daf-b66a-1d778f5964f8  72fe360b-cce6-4daf-b66a-1d778f5964f8   \n",
       "6  df594cf4-9a0c-4488-bcb3-68f41e2d5a16  df594cf4-9a0c-4488-bcb3-68f41e2d5a16   \n",
       "\n",
       "                              source_id  model decoding repetition_penalty  \\\n",
       "0  e5e058ce-be2b-459d-af36-32532aaba5ff  human      NaN                NaN   \n",
       "1  f95b107b-d176-4af5-90f7-4d0bb20caf93  human      NaN                NaN   \n",
       "2  856d8972-9e3d-4544-babc-0fe16f21e04d  human      NaN                NaN   \n",
       "3  fbc8a5ea-90fa-47b8-8fa7-73dd954f1524  human      NaN                NaN   \n",
       "4  72c41b8d-0069-4886-b734-a4000ffca286  human      NaN                NaN   \n",
       "5  72fe360b-cce6-4daf-b66a-1d778f5964f8  human      NaN                NaN   \n",
       "6  df594cf4-9a0c-4488-bcb3-68f41e2d5a16  human      NaN                NaN   \n",
       "\n",
       "  attack     domain                                              title prompt  \\\n",
       "0   none  abstracts  FUTURE-AI: Guiding Principles and Consensus Re...    NaN   \n",
       "1   none  abstracts  EdgeFlow: Achieving Practical Interactive Segm...    NaN   \n",
       "2   none  abstracts  Semi-supervised Contrastive Learning for Label...    NaN   \n",
       "3   none  abstracts  Combo Loss: Handling Input and Output Imbalanc...    NaN   \n",
       "4   none  abstracts  Attention-Based 3D Seismic Fault Segmentation ...    NaN   \n",
       "5   none  abstracts   Segmenter: Transformer for Semantic Segmentation    NaN   \n",
       "6   none  abstracts  Mining Contextual Information Beyond Image for...    NaN   \n",
       "\n",
       "                                          generation  \n",
       "0  The recent advancements in artificial intellig...  \n",
       "1  High-quality training data play a key role in ...  \n",
       "2  The success of deep learning methods in medica...  \n",
       "3  Simultaneous segmentation of multiple organs f...  \n",
       "4  Detection faults in seismic data is a crucial ...  \n",
       "5  Image segmentation is often ambiguous at the l...  \n",
       "6  This paper studies the context aggregation pro...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(or_train_noadv_df.head(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9b9a366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>prompt</th>\n",
       "      <th>generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e5e058ce-be2b-459d-af36-32532aaba5ff</td>\n",
       "      <td>human</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The recent advancements in artificial intellig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f95b107b-d176-4af5-90f7-4d0bb20caf93</td>\n",
       "      <td>human</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>EdgeFlow: Achieving Practical Interactive Segm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High-quality training data play a key role in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>856d8972-9e3d-4544-babc-0fe16f21e04d</td>\n",
       "      <td>human</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Semi-supervised Contrastive Learning for Label...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The success of deep learning methods in medica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fbc8a5ea-90fa-47b8-8fa7-73dd954f1524</td>\n",
       "      <td>human</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Combo Loss: Handling Input and Output Imbalanc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Simultaneous segmentation of multiple organs f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72c41b8d-0069-4886-b734-a4000ffca286</td>\n",
       "      <td>human</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Attention-Based 3D Seismic Fault Segmentation ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Detection faults in seismic data is a crucial ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>72fe360b-cce6-4daf-b66a-1d778f5964f8</td>\n",
       "      <td>human</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Segmenter: Transformer for Semantic Segmentation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Image segmentation is often ambiguous at the l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>df594cf4-9a0c-4488-bcb3-68f41e2d5a16</td>\n",
       "      <td>human</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Mining Contextual Information Beyond Image for...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This paper studies the context aggregation pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  model     domain  \\\n",
       "0  e5e058ce-be2b-459d-af36-32532aaba5ff  human  abstracts   \n",
       "1  f95b107b-d176-4af5-90f7-4d0bb20caf93  human  abstracts   \n",
       "2  856d8972-9e3d-4544-babc-0fe16f21e04d  human  abstracts   \n",
       "3  fbc8a5ea-90fa-47b8-8fa7-73dd954f1524  human  abstracts   \n",
       "4  72c41b8d-0069-4886-b734-a4000ffca286  human  abstracts   \n",
       "5  72fe360b-cce6-4daf-b66a-1d778f5964f8  human  abstracts   \n",
       "6  df594cf4-9a0c-4488-bcb3-68f41e2d5a16  human  abstracts   \n",
       "\n",
       "                                               title prompt  \\\n",
       "0  FUTURE-AI: Guiding Principles and Consensus Re...    NaN   \n",
       "1  EdgeFlow: Achieving Practical Interactive Segm...    NaN   \n",
       "2  Semi-supervised Contrastive Learning for Label...    NaN   \n",
       "3  Combo Loss: Handling Input and Output Imbalanc...    NaN   \n",
       "4  Attention-Based 3D Seismic Fault Segmentation ...    NaN   \n",
       "5   Segmenter: Transformer for Semantic Segmentation    NaN   \n",
       "6  Mining Contextual Information Beyond Image for...    NaN   \n",
       "\n",
       "                                          generation  \n",
       "0  The recent advancements in artificial intellig...  \n",
       "1  High-quality training data play a key role in ...  \n",
       "2  The success of deep learning methods in medica...  \n",
       "3  Simultaneous segmentation of multiple organs f...  \n",
       "4  Detection faults in seismic data is a crucial ...  \n",
       "5  Image segmentation is often ambiguous at the l...  \n",
       "6  This paper studies the context aggregation pro...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "intCols = ['id','model', 'domain', 'title', 'prompt', 'generation']\n",
    "# print(\"Visualizar columnas específicas:\")\n",
    "# train_noadv_df = or_train_noadv_df[or_train_noadv_df['model'] != 'human']\n",
    "\n",
    "# Copia del dataframe con columnas específicas\n",
    "train_noadv_df = or_train_noadv_df.copy()\n",
    "train_noadv_df = train_noadv_df[intCols]\n",
    "\n",
    "display(train_noadv_df.head(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d852ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información del dataset de entrenamiento:\n",
      "Forma del dataset: (467985, 6)\n",
      "Columnas: ['id', 'model', 'domain', 'title', 'prompt', 'generation']\n",
      "Modelos unicos: ['human' 'llama-chat' 'mpt' 'mpt-chat' 'gpt2' 'mistral' 'mistral-chat'\n",
      " 'gpt3' 'cohere' 'chatgpt' 'gpt4' 'cohere-chat']\n",
      "Dominios unicos: ['abstracts' 'books' 'news' 'poetry' 'recipes' 'reddit' 'reviews' 'wiki']\n"
     ]
    }
   ],
   "source": [
    "print(\"Información del dataset de entrenamiento:\")\n",
    "print(f\"Forma del dataset: {train_noadv_df.shape}\")\n",
    "print(f\"Columnas: {list(train_noadv_df.columns)}\")\n",
    "print(f\"Modelos unicos: {train_noadv_df['model'].unique()}\")\n",
    "print(f\"Dominios unicos: {train_noadv_df['domain'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06b89d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>prompt</th>\n",
       "      <th>generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>2bd98bd7-3356-43bf-8c5d-69ef336d0536</td>\n",
       "      <td>llama-chat</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
       "      <td>Write the abstract for the academic paper titl...</td>\n",
       "      <td>In the paper \"FUTURE-AI: Guiding Principles an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>e8bdc461-3ff2-4d68-8c7b-cdbc086f62b3</td>\n",
       "      <td>llama-chat</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
       "      <td>Write the abstract for the academic paper titl...</td>\n",
       "      <td>In the paper \"Future-AI: Guiding Principles an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>ee968d29-ce73-4c5d-804d-0a0efec4bea4</td>\n",
       "      <td>llama-chat</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>EdgeFlow: Achieving Practical Interactive Segm...</td>\n",
       "      <td>Write the abstract for the academic paper titl...</td>\n",
       "      <td>In this paper, we present EdgeFlow, a novel ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>3d24eb90-f540-490f-81c8-e4a24fd49ad7</td>\n",
       "      <td>llama-chat</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>EdgeFlow: Achieving Practical Interactive Segm...</td>\n",
       "      <td>Write the abstract for the academic paper titl...</td>\n",
       "      <td>In this paper, we present a novel approach to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>5f817bbe-4fb4-4011-a1e9-fcf12990f450</td>\n",
       "      <td>llama-chat</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Semi-supervised Contrastive Learning for Label...</td>\n",
       "      <td>Write the abstract for the academic paper titl...</td>\n",
       "      <td>In this paper, we propose a novel approach to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>7389e65b-2e27-4b90-999a-53e28b773315</td>\n",
       "      <td>llama-chat</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Semi-supervised Contrastive Learning for Label...</td>\n",
       "      <td>Write the abstract for the academic paper titl...</td>\n",
       "      <td>In this paper, we propose a novel approach to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>8b79a378-67db-48e8-8950-4d3215cfef16</td>\n",
       "      <td>llama-chat</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Combo Loss: Handling Input and Output Imbalanc...</td>\n",
       "      <td>Write the abstract for the academic paper titl...</td>\n",
       "      <td>In the field of medical image segmentation, im...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id       model     domain  \\\n",
       "493  2bd98bd7-3356-43bf-8c5d-69ef336d0536  llama-chat  abstracts   \n",
       "494  e8bdc461-3ff2-4d68-8c7b-cdbc086f62b3  llama-chat  abstracts   \n",
       "495  ee968d29-ce73-4c5d-804d-0a0efec4bea4  llama-chat  abstracts   \n",
       "496  3d24eb90-f540-490f-81c8-e4a24fd49ad7  llama-chat  abstracts   \n",
       "497  5f817bbe-4fb4-4011-a1e9-fcf12990f450  llama-chat  abstracts   \n",
       "498  7389e65b-2e27-4b90-999a-53e28b773315  llama-chat  abstracts   \n",
       "499  8b79a378-67db-48e8-8950-4d3215cfef16  llama-chat  abstracts   \n",
       "\n",
       "                                                 title  \\\n",
       "493  FUTURE-AI: Guiding Principles and Consensus Re...   \n",
       "494  FUTURE-AI: Guiding Principles and Consensus Re...   \n",
       "495  EdgeFlow: Achieving Practical Interactive Segm...   \n",
       "496  EdgeFlow: Achieving Practical Interactive Segm...   \n",
       "497  Semi-supervised Contrastive Learning for Label...   \n",
       "498  Semi-supervised Contrastive Learning for Label...   \n",
       "499  Combo Loss: Handling Input and Output Imbalanc...   \n",
       "\n",
       "                                                prompt  \\\n",
       "493  Write the abstract for the academic paper titl...   \n",
       "494  Write the abstract for the academic paper titl...   \n",
       "495  Write the abstract for the academic paper titl...   \n",
       "496  Write the abstract for the academic paper titl...   \n",
       "497  Write the abstract for the academic paper titl...   \n",
       "498  Write the abstract for the academic paper titl...   \n",
       "499  Write the abstract for the academic paper titl...   \n",
       "\n",
       "                                            generation  \n",
       "493  In the paper \"FUTURE-AI: Guiding Principles an...  \n",
       "494  In the paper \"Future-AI: Guiding Principles an...  \n",
       "495  In this paper, we present EdgeFlow, a novel ap...  \n",
       "496  In this paper, we present a novel approach to ...  \n",
       "497  In this paper, we propose a novel approach to ...  \n",
       "498  In this paper, we propose a novel approach to ...  \n",
       "499  In the field of medical image segmentation, im...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# intCols = ['model', 'domain', 'title', 'prompt', 'generation']\n",
    "# print(\"Visualizar columnas específicas:\")\n",
    "filtered = train_noadv_df[train_noadv_df['model'] != 'human']\n",
    "\n",
    "display(filtered.head(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b12f1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>domain</th>\n",
       "      <th>generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>The recent advancements in artificial intelligence (AI) combined with the\\nextensive amount of data generated by today's clinical systems, has led to the\\ndevelopment of imaging AI solutions across the whole value chain of medical\\nimaging, including image reconstruction, medical image segmentation,\\nimage-based diagnosis and treatment planning. Notwithstanding the successes and\\nfuture potential of AI in medical imaging, many stakeholders are concerned of\\nthe potential risks and ethical implications of imaging AI solutions, which are\\nperceived as complex, opaque, and difficult to comprehend, utilise, and trust\\nin critical clinical applications. Despite these concerns and risks, there are\\ncurrently no concrete guidelines and best practices for guiding future AI\\ndevelopments in medical imaging towards increased trust, safety and adoption.\\nTo bridge this gap, this paper introduces a careful selection of guiding\\nprinciples drawn from the accumulated experiences, consensus, and best\\npractices from five large European projects on AI in Health Imaging. These\\nguiding principles are named FUTURE-AI and its building blocks consist of (i)\\nFairness, (ii) Universality, (iii) Traceability, (iv) Usability, (v) Robustness\\nand (vi) Explainability. In a step-by-step approach, these guidelines are\\nfurther translated into a framework of concrete recommendations for specifying,\\ndeveloping, evaluating, and deploying technically, clinically and ethically\\ntrustworthy AI solutions into clinical practice.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>human</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>High-quality training data play a key role in image segmentation tasks.\\nUsually, pixel-level annotations are expensive, laborious and time-consuming\\nfor the large volume of training data. To reduce labelling cost and improve\\nsegmentation quality, interactive segmentation methods have been proposed,\\nwhich provide the result with just a few clicks. However, their performance\\ndoes not meet the requirements of practical segmentation tasks in terms of\\nspeed and accuracy. In this work, we propose EdgeFlow, a novel architecture\\nthat fully utilizes interactive information of user clicks with edge-guided\\nflow. Our method achieves state-of-the-art performance without any\\npost-processing or iterative optimization scheme. Comprehensive experiments on\\nbenchmarks also demonstrate the superiority of our method. In addition, with\\nthe proposed method, we develop an efficient interactive segmentation tool for\\npractical data annotation tasks. The source code and tool is avaliable at\\nhttps://github.com/PaddlePaddle/PaddleSeg.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>human</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>The success of deep learning methods in medical image segmentation tasks\\nheavily depends on a large amount of labeled data to supervise the training. On\\nthe other hand, the annotation of biomedical images requires domain knowledge\\nand can be laborious. Recently, contrastive learning has demonstrated great\\npotential in learning latent representation of images even without any label.\\nExisting works have explored its application to biomedical image segmentation\\nwhere only a small portion of data is labeled, through a pre-training phase\\nbased on self-supervised contrastive learning without using any labels followed\\nby a supervised fine-tuning phase on the labeled portion of data only. In this\\npaper, we establish that by including the limited label in formation in the\\npre-training phase, it is possible to boost the performance of contrastive\\nlearning. We propose a supervised local contrastive loss that leverages limited\\npixel-wise annotation to force pixels with the same label to gather around in\\nthe embedding space. Such loss needs pixel-wise computation which can be\\nexpensive for large images, and we further propose two strategies, downsampling\\nand block division, to address the issue. We evaluate our methods on two public\\nbiomedical image datasets of different modalities. With different amounts of\\nlabeled data, our methods consistently outperform the state-of-the-art\\ncontrast-based methods and other semi-supervised learning techniques.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model     domain  \\\n",
       "0  human  abstracts   \n",
       "1  human  abstracts   \n",
       "2  human  abstracts   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        generation  \n",
       "0  The recent advancements in artificial intelligence (AI) combined with the\\nextensive amount of data generated by today's clinical systems, has led to the\\ndevelopment of imaging AI solutions across the whole value chain of medical\\nimaging, including image reconstruction, medical image segmentation,\\nimage-based diagnosis and treatment planning. Notwithstanding the successes and\\nfuture potential of AI in medical imaging, many stakeholders are concerned of\\nthe potential risks and ethical implications of imaging AI solutions, which are\\nperceived as complex, opaque, and difficult to comprehend, utilise, and trust\\nin critical clinical applications. Despite these concerns and risks, there are\\ncurrently no concrete guidelines and best practices for guiding future AI\\ndevelopments in medical imaging towards increased trust, safety and adoption.\\nTo bridge this gap, this paper introduces a careful selection of guiding\\nprinciples drawn from the accumulated experiences, consensus, and best\\npractices from five large European projects on AI in Health Imaging. These\\nguiding principles are named FUTURE-AI and its building blocks consist of (i)\\nFairness, (ii) Universality, (iii) Traceability, (iv) Usability, (v) Robustness\\nand (vi) Explainability. In a step-by-step approach, these guidelines are\\nfurther translated into a framework of concrete recommendations for specifying,\\ndeveloping, evaluating, and deploying technically, clinically and ethically\\ntrustworthy AI solutions into clinical practice.  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       High-quality training data play a key role in image segmentation tasks.\\nUsually, pixel-level annotations are expensive, laborious and time-consuming\\nfor the large volume of training data. To reduce labelling cost and improve\\nsegmentation quality, interactive segmentation methods have been proposed,\\nwhich provide the result with just a few clicks. However, their performance\\ndoes not meet the requirements of practical segmentation tasks in terms of\\nspeed and accuracy. In this work, we propose EdgeFlow, a novel architecture\\nthat fully utilizes interactive information of user clicks with edge-guided\\nflow. Our method achieves state-of-the-art performance without any\\npost-processing or iterative optimization scheme. Comprehensive experiments on\\nbenchmarks also demonstrate the superiority of our method. In addition, with\\nthe proposed method, we develop an efficient interactive segmentation tool for\\npractical data annotation tasks. The source code and tool is avaliable at\\nhttps://github.com/PaddlePaddle/PaddleSeg.  \n",
       "2                                              The success of deep learning methods in medical image segmentation tasks\\nheavily depends on a large amount of labeled data to supervise the training. On\\nthe other hand, the annotation of biomedical images requires domain knowledge\\nand can be laborious. Recently, contrastive learning has demonstrated great\\npotential in learning latent representation of images even without any label.\\nExisting works have explored its application to biomedical image segmentation\\nwhere only a small portion of data is labeled, through a pre-training phase\\nbased on self-supervised contrastive learning without using any labels followed\\nby a supervised fine-tuning phase on the labeled portion of data only. In this\\npaper, we establish that by including the limited label in formation in the\\npre-training phase, it is possible to boost the performance of contrastive\\nlearning. We propose a supervised local contrastive loss that leverages limited\\npixel-wise annotation to force pixels with the same label to gather around in\\nthe embedding space. Such loss needs pixel-wise computation which can be\\nexpensive for large images, and we further propose two strategies, downsampling\\nand block division, to address the issue. We evaluate our methods on two public\\nbiomedical image datasets of different modalities. With different amounts of\\nlabeled data, our methods consistently outperform the state-of-the-art\\ncontrast-based methods and other semi-supervised learning techniques.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Opción 1: Configurar pandas para mostrar más contenido\n",
    "pd.set_option('display.max_colwidth', None)  # Sin límite de ancho\n",
    "pd.set_option('display.max_rows', None)      # Sin límite de filas (usar con cuidado)\n",
    "\n",
    "complex_filter = train_noadv_df[(train_noadv_df['model'] == 'human') &\n",
    "                                (train_noadv_df['domain'] == 'abstracts')]\n",
    "\n",
    "# Ahora al mostrar el dataframe, verás el contenido completo\n",
    "display(complex_filter[['model', 'domain', 'generation']].head(3))\n",
    "\n",
    "# Si quieres restaurar los valores por defecto de pandas:\n",
    "pd.reset_option('display.max_colwidth')\n",
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5c367a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtro complejo: 16933\n",
      "model\n",
      "human    13371\n",
      "gpt4      3562\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Opción 5: Filtrar con condiciones complejas (OR entre grupos)\n",
    "complex_filter = train_noadv_df[(train_noadv_df['model'] == 'human') | \n",
    "                                ((train_noadv_df['model'] == 'gpt4') & \n",
    "                                 (train_noadv_df['domain'] == 'books'))]\n",
    "print(f\"\\nFiltro complejo: {len(complex_filter)}\")\n",
    "print(complex_filter['model'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bda8357",
   "metadata": {},
   "source": [
    "## Uso de Stylometrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bd2b93",
   "metadata": {},
   "source": [
    "### Test de extracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dedb42b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model</th>\n",
       "      <th>domain</th>\n",
       "      <th>generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110956</th>\n",
       "      <td>c4059838-c14e-4b84-b75c-12bc0bd2f34a</td>\n",
       "      <td>cohere</td>\n",
       "      <td>books</td>\n",
       "      <td>The story centers on Charles, the husband of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363000</th>\n",
       "      <td>c5001dc3-5baa-4abf-8a1b-2e0bf6d7c77d</td>\n",
       "      <td>gpt3</td>\n",
       "      <td>reddit</td>\n",
       "      <td>\\n\\nJust wondering where do I start?\\n\\nI've b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172379</th>\n",
       "      <td>42bb8f1e-60ec-428d-800c-e9059a0efdab</td>\n",
       "      <td>gpt3</td>\n",
       "      <td>news</td>\n",
       "      <td>\\n\\nLasers are being used to create an ultra-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200619</th>\n",
       "      <td>6a2721a4-d15e-44a9-9f09-e48e60e17a4d</td>\n",
       "      <td>llama-chat</td>\n",
       "      <td>poetry</td>\n",
       "      <td>With eager hands, we plant the seeds,\\nIn fert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27573</th>\n",
       "      <td>4a64da9c-2df8-4f58-91ee-2f9192cc5667</td>\n",
       "      <td>mistral</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Medical image analysis has experienced an expl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          id       model     domain  \\\n",
       "110956  c4059838-c14e-4b84-b75c-12bc0bd2f34a      cohere      books   \n",
       "363000  c5001dc3-5baa-4abf-8a1b-2e0bf6d7c77d        gpt3     reddit   \n",
       "172379  42bb8f1e-60ec-428d-800c-e9059a0efdab        gpt3       news   \n",
       "200619  6a2721a4-d15e-44a9-9f09-e48e60e17a4d  llama-chat     poetry   \n",
       "27573   4a64da9c-2df8-4f58-91ee-2f9192cc5667     mistral  abstracts   \n",
       "\n",
       "                                               generation  \n",
       "110956   The story centers on Charles, the husband of ...  \n",
       "363000  \\n\\nJust wondering where do I start?\\n\\nI've b...  \n",
       "172379  \\n\\nLasers are being used to create an ultra-f...  \n",
       "200619  With eager hands, we plant the seeds,\\nIn fert...  \n",
       "27573   Medical image analysis has experienced an expl...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get sample dataframe 'generation'\n",
    "\n",
    "filtered_by_domain = train_noadv_df[\n",
    "    (train_noadv_df['domain'] != 'recipes')\n",
    "    ]\n",
    "generation_sample = filtered_by_domain[['id', 'model', 'domain', 'generation']].sample(n=5, random_state=3)\n",
    "\n",
    "display(generation_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1467c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The story centers on Charles, the husband of Alice, who is visiting his new estate. He insists that she stay in the chateau while he travels to Paris on business. Charles abruptly ends his trip and returns home, surprising Alice. He announces that he has sold the estate, and they will have to leave at once. Then he hands Alice a key he says he found on the path leading to the chateau.\n",
      "\n",
      "Alice rejoices at the news of their departure, but is perplexed by the key. Charles vehemently tells her to discard it, but she cannot bring herself to throw it away. Later, while exploring the chateau, she discovers a room that is locked. Curiosity gets the better of her, and she tries the key. It fits! Alice is shocked to discover the room is full of blood-stained weapons and dead bodies. In a moment of madness, she realizes that Charles has killed his previous wives, and she must dispose of the key lest she become his next victim.\n",
      "\n",
      "Alice returns the key to Charles and tells him it does not fit any of the doors. He is furious, but soon calms down. He insists that she search the room more thoroughly. Suddenly, Alice notices that the key has returned to its original spot—it has magically reappeared. Charles snatches it up and tells Alice that henceforth she will be locked in the room while he is away. Alice is terrified, but she seems to have no choice.\n",
      "\n",
      "When Charles leaves, Alice is haunted by the memory of the murdered wives. The bodies seem to come to life, and the ghosts plead with Alice to avenge their deaths. Soon, Alice fashions a noose and hanged herself from the peal of the bell tower, joining the other wives. Upon his return, Charles, who has genuinely loved Alice, is horrified by her death. He vows to never marry again, and spends the rest of his life alone and haunted by his victims.\n",
      "[OK] Total de oraciones: 23\n"
     ]
    }
   ],
   "source": [
    "print(generation_sample['generation'].iloc[0])\n",
    "outputList = split_text_into_sentences(generation_sample['generation'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c13c6b7",
   "metadata": {},
   "source": [
    "#### Extracción de rasgos en un registro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86531196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The story centers on Charles, the husband of Alice, who is visiting his new estate.\n",
      "-----\n",
      "He insists that she stay in the chateau while he travels to Paris on business.\n",
      "-----\n",
      "Charles abruptly ends his trip and returns home, surprising Alice.\n",
      "-----\n",
      "He announces that he has sold the estate, and they will have to leave at once.\n",
      "-----\n",
      "Then he hands Alice a key he says he found on the path leading to the chateau.\n",
      "-----\n",
      "Alice rejoices at the news of their departure, but is perplexed by the key.\n",
      "-----\n",
      "Charles vehemently tells her to discard it, but she cannot bring herself to throw it away.\n",
      "-----\n",
      "Later, while exploring the chateau, she discovers a room that is locked.\n",
      "-----\n",
      "Curiosity gets the better of her, and she tries the key.\n",
      "-----\n",
      "It fits!\n",
      "-----\n",
      "Alice is shocked to discover the room is full of blood-stained weapons and dead bodies.\n",
      "-----\n",
      "In a moment of madness, she realizes that Charles has killed his previous wives, and she must dispose of the key lest she become his next victim.\n",
      "-----\n",
      "Alice returns the key to Charles and tells him it does not fit any of the doors.\n",
      "-----\n",
      "He is furious, but soon calms down.\n",
      "-----\n",
      "He insists that she search the room more thoroughly.\n",
      "-----\n",
      "Suddenly, Alice notices that the key has returned to its original spot—it has magically reappeared.\n",
      "-----\n",
      "Charles snatches it up and tells Alice that henceforth she will be locked in the room while he is away.\n",
      "-----\n",
      "Alice is terrified, but she seems to have no choice.\n",
      "-----\n",
      "When Charles leaves, Alice is haunted by the memory of the murdered wives.\n",
      "-----\n",
      "The bodies seem to come to life, and the ghosts plead with Alice to avenge their deaths.\n",
      "-----\n",
      "Soon, Alice fashions a noose and hanged herself from the peal of the bell tower, joining the other wives.\n",
      "-----\n",
      "Upon his return, Charles, who has genuinely loved Alice, is horrified by her death.\n",
      "-----\n",
      "He vows to never marry again, and spends the rest of his life alone and haunted by his victims.\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "for sentence in outputList:\n",
    "    print(sentence)\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33e2c8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrar contenido de la carpeta de salida antes de guardar nuevos resultados\n",
    "def reset_output_dir(output_dir):\n",
    "    # output_dir = \"testVisual/single\"\n",
    "    if os.path.exists(output_dir):\n",
    "        shutil.rmtree(output_dir)\n",
    "    os.makedirs(output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d75fe6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\spacy\\util.py:910: UserWarning: [W095] Model 'en_core_web_trf' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.2). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "  0%|          | 0/23 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 23/23 [00:03<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved in location: testVisual\\single\\sm_output1.csv\n",
      "File saved in location: testVisual\\single\\sm_debug1.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                                 text  POS_VERB  POS_NOUN  \\\n",
       " 0   The story centers on Charles, the husband of A...  0.200000  0.200000   \n",
       " 1   He insists that she stay in the chateau while ...  0.200000  0.133333   \n",
       " 2   Charles abruptly ends his trip and returns hom...  0.300000  0.100000   \n",
       " 3   He announces that he has sold the estate, and ...  0.375000  0.062500   \n",
       " 4   Then he hands Alice a key he says he found on ...  0.235294  0.176471   \n",
       " 5   Alice rejoices at the news of their departure,...  0.214286  0.214286   \n",
       " 6   Charles vehemently tells her to discard it, bu...  0.312500  0.000000   \n",
       " 7   Later, while exploring the chateau, she discov...  0.333333  0.166667   \n",
       " 8   Curiosity gets the better of her, and she trie...  0.181818  0.181818   \n",
       " 9                                            It fits!  0.500000  0.000000   \n",
       " 10  Alice is shocked to discover the room is full ...  0.333333  0.266667   \n",
       " 11  In a moment of madness, she realizes that Char...  0.222222  0.185185   \n",
       " 12  Alice returns the key to Charles and tells him...  0.235294  0.117647   \n",
       " 13                He is furious, but soon calms down.  0.285714  0.000000   \n",
       " 14  He insists that she search the room more thoro...  0.222222  0.111111   \n",
       " 15  Suddenly, Alice notices that the key has retur...  0.333333  0.133333   \n",
       " 16  Charles snatches it up and tells Alice that he...  0.300000  0.050000   \n",
       " 17  Alice is terrified, but she seems to have no c...  0.400000  0.100000   \n",
       " 18  When Charles leaves, Alice is haunted by the m...  0.307692  0.153846   \n",
       " 19  The bodies seem to come to life, and the ghost...  0.235294  0.235294   \n",
       " 20  Soon, Alice fashions a noose and hanged hersel...  0.157895  0.263158   \n",
       " 21  Upon his return, Charles, who has genuinely lo...  0.285714  0.142857   \n",
       " 22  He vows to never marry again, and spends the r...  0.210526  0.157895   \n",
       " \n",
       "      POS_ADJ   POS_ADV   POS_DET  POS_INTJ  POS_CONJ  POS_PART  POS_NUM  ...  \\\n",
       " 0   0.066667  0.000000  0.133333       0.0  0.000000  0.000000      0.0  ...   \n",
       " 1   0.000000  0.000000  0.066667       0.0  0.133333  0.000000      0.0  ...   \n",
       " 2   0.000000  0.200000  0.000000       0.0  0.100000  0.000000      0.0  ...   \n",
       " 3   0.000000  0.062500  0.062500       0.0  0.125000  0.062500      0.0  ...   \n",
       " 4   0.000000  0.058824  0.176471       0.0  0.000000  0.000000      0.0  ...   \n",
       " 5   0.000000  0.000000  0.142857       0.0  0.071429  0.000000      0.0  ...   \n",
       " 6   0.000000  0.125000  0.000000       0.0  0.062500  0.187500      0.0  ...   \n",
       " 7   0.000000  0.083333  0.166667       0.0  0.083333  0.000000      0.0  ...   \n",
       " 8   0.090909  0.000000  0.181818       0.0  0.090909  0.000000      0.0  ...   \n",
       " 9   0.000000  0.000000  0.000000       0.0  0.000000  0.000000      0.0  ...   \n",
       " 10  0.133333  0.000000  0.066667       0.0  0.066667  0.066667      0.0  ...   \n",
       " 11  0.074074  0.000000  0.074074       0.0  0.111111  0.000000      0.0  ...   \n",
       " 12  0.000000  0.000000  0.117647       0.0  0.058824  0.058824      0.0  ...   \n",
       " 13  0.142857  0.142857  0.000000       0.0  0.142857  0.000000      0.0  ...   \n",
       " 14  0.000000  0.222222  0.111111       0.0  0.111111  0.000000      0.0  ...   \n",
       " 15  0.066667  0.133333  0.066667       0.0  0.066667  0.000000      0.0  ...   \n",
       " 16  0.000000  0.100000  0.050000       0.0  0.150000  0.000000      0.0  ...   \n",
       " 17  0.000000  0.000000  0.100000       0.0  0.100000  0.100000      0.0  ...   \n",
       " 18  0.000000  0.000000  0.153846       0.0  0.076923  0.000000      0.0  ...   \n",
       " 19  0.000000  0.000000  0.117647       0.0  0.058824  0.117647      0.0  ...   \n",
       " 20  0.052632  0.052632  0.210526       0.0  0.052632  0.000000      0.0  ...   \n",
       " 21  0.000000  0.071429  0.000000       0.0  0.071429  0.000000      0.0  ...   \n",
       " 22  0.052632  0.105263  0.052632       0.0  0.105263  0.052632      0.0  ...   \n",
       " \n",
       "           RE   ASF       ASM      OM  RCI       DMC    OR       QAS   PA   PR  \n",
       " 0   0.000000  0.00  0.000000  0.0000  0.0  0.000000  0.00  0.200000  0.0  0.0  \n",
       " 1   0.000000  0.00  0.000000  0.0000  0.0  0.000000  0.00  0.133333  0.0  0.0  \n",
       " 2   0.000000  0.00  0.000000  0.0000  0.0  0.000000  0.00  0.000000  0.0  0.0  \n",
       " 3   0.000000  0.00  0.000000  0.0000  0.0  0.000000  0.00  0.062500  0.0  0.0  \n",
       " 4   0.000000  0.00  0.000000  0.0000  0.0  0.000000  0.00  0.117647  0.0  0.0  \n",
       " 5   0.000000  0.00  0.000000  0.0000  0.0  0.000000  0.00  0.142857  0.0  0.0  \n",
       " 6   0.000000  0.00  0.000000  0.0625  0.0  0.000000  0.00  0.000000  0.0  0.0  \n",
       " 7   0.000000  0.00  0.000000  0.0000  0.0  0.000000  0.00  0.083333  0.0  0.0  \n",
       " 8   0.000000  0.00  0.000000  0.0000  0.0  0.000000  0.00  0.181818  0.0  0.0  \n",
       " 9   0.000000  0.00  0.000000  0.0000  0.0  0.000000  0.00  0.000000  0.0  0.0  \n",
       " 10  0.000000  0.00  0.000000  0.0000  0.0  0.066667  0.00  0.133333  0.0  0.0  \n",
       " 11  0.037037  0.00  0.000000  0.0000  0.0  0.000000  0.00  0.037037  0.0  0.0  \n",
       " 12  0.000000  0.00  0.058824  0.0000  0.0  0.000000  0.00  0.117647  0.0  0.0  \n",
       " 13  0.142857  0.00  0.000000  0.0000  0.0  0.000000  0.00  0.000000  0.0  0.0  \n",
       " 14  0.000000  0.00  0.000000  0.0000  0.0  0.000000  0.00  0.111111  0.0  0.0  \n",
       " 15  0.000000  0.00  0.000000  0.0000  0.0  0.000000  0.00  0.066667  0.0  0.0  \n",
       " 16  0.050000  0.05  0.000000  0.0000  0.0  0.000000  0.05  0.050000  0.0  0.0  \n",
       " 17  0.000000  0.00  0.000000  0.0000  0.0  0.000000  0.00  0.000000  0.0  0.0  \n",
       " 18  0.076923  0.00  0.000000  0.0000  0.0  0.000000  0.00  0.153846  0.0  0.0  \n",
       " 19  0.000000  0.00  0.000000  0.0000  0.0  0.000000  0.00  0.117647  0.0  0.0  \n",
       " 20  0.000000  0.00  0.000000  0.0000  0.0  0.000000  0.00  0.157895  0.0  0.0  \n",
       " 21  0.000000  0.00  0.071429  0.0000  0.0  0.000000  0.00  0.000000  0.0  0.0  \n",
       " 22  0.000000  0.00  0.000000  0.0000  0.0  0.000000  0.00  0.052632  0.0  0.0  \n",
       " \n",
       " [23 rows x 197 columns],\n",
       "                                                  text  \\\n",
       " 0   The story centers on Charles, the husband of A...   \n",
       " 1   He insists that she stay in the chateau while ...   \n",
       " 2   Charles abruptly ends his trip and returns hom...   \n",
       " 3   He announces that he has sold the estate, and ...   \n",
       " 4   Then he hands Alice a key he says he found on ...   \n",
       " 5   Alice rejoices at the news of their departure,...   \n",
       " 6   Charles vehemently tells her to discard it, bu...   \n",
       " 7   Later, while exploring the chateau, she discov...   \n",
       " 8   Curiosity gets the better of her, and she trie...   \n",
       " 9                                            It fits!   \n",
       " 10  Alice is shocked to discover the room is full ...   \n",
       " 11  In a moment of madness, she realizes that Char...   \n",
       " 12  Alice returns the key to Charles and tells him...   \n",
       " 13                He is furious, but soon calms down.   \n",
       " 14  He insists that she search the room more thoro...   \n",
       " 15  Suddenly, Alice notices that the key has retur...   \n",
       " 16  Charles snatches it up and tells Alice that he...   \n",
       " 17  Alice is terrified, but she seems to have no c...   \n",
       " 18  When Charles leaves, Alice is haunted by the m...   \n",
       " 19  The bodies seem to come to life, and the ghost...   \n",
       " 20  Soon, Alice fashions a noose and hanged hersel...   \n",
       " 21  Upon his return, Charles, who has genuinely lo...   \n",
       " 22  He vows to never marry again, and spends the r...   \n",
       " \n",
       "                                           POS_VERB  \\\n",
       " 0                          [centers, is, visiting]   \n",
       " 1                         [insists, stay, travels]   \n",
       " 2                      [ends, returns, surprising]   \n",
       " 3        [announces, has, sold, will, have, leave]   \n",
       " 4                    [hands, says, found, leading]   \n",
       " 5                        [rejoices, is, perplexed]   \n",
       " 6              [tells, discard, can, bring, throw]   \n",
       " 7               [exploring, discovers, is, locked]   \n",
       " 8                                    [gets, tries]   \n",
       " 9                                           [fits]   \n",
       " 10            [is, shocked, discover, is, stained]   \n",
       " 11  [realizes, has, killed, must, dispose, become]   \n",
       " 12                     [returns, tells, does, fit]   \n",
       " 13                                     [is, calms]   \n",
       " 14                               [insists, search]   \n",
       " 15       [notices, has, returned, has, reappeared]   \n",
       " 16         [snatches, tells, will, be, locked, is]   \n",
       " 17                    [is, terrified, seems, have]   \n",
       " 18                 [leaves, is, haunted, murdered]   \n",
       " 19                     [seem, come, plead, avenge]   \n",
       " 20                     [fashions, hanged, joining]   \n",
       " 21                     [has, loved, is, horrified]   \n",
       " 22                  [vows, marry, spends, haunted]   \n",
       " \n",
       "                                  POS_NOUN           POS_ADJ  \\\n",
       " 0                [story, husband, estate]             [new]   \n",
       " 1                     [chateau, business]                []   \n",
       " 2                                  [trip]                []   \n",
       " 3                                [estate]                []   \n",
       " 4                    [key, path, chateau]                []   \n",
       " 5                  [news, departure, key]                []   \n",
       " 6                                      []                []   \n",
       " 7                         [chateau, room]                []   \n",
       " 8                        [Curiosity, key]          [better]   \n",
       " 9                                      []                []   \n",
       " 10         [room, blood, weapons, bodies]      [full, dead]   \n",
       " 11  [moment, madness, wives, key, victim]  [previous, next]   \n",
       " 12                           [key, doors]                []   \n",
       " 13                                     []         [furious]   \n",
       " 14                                 [room]                []   \n",
       " 15                            [key, spot]        [original]   \n",
       " 16                                 [room]                []   \n",
       " 17                               [choice]                []   \n",
       " 18                        [memory, wives]                []   \n",
       " 19         [bodies, life, ghosts, deaths]                []   \n",
       " 20      [noose, peal, bell, tower, wives]           [other]   \n",
       " 21                        [return, death]                []   \n",
       " 22                  [rest, life, victims]           [alone]   \n",
       " \n",
       "                   POS_ADV             POS_DET POS_INTJ            POS_CONJ  \\\n",
       " 0                      []          [The, the]       []                  []   \n",
       " 1                      []               [the]       []       [that, while]   \n",
       " 2        [abruptly, home]                  []       []               [and]   \n",
       " 3                  [once]               [the]       []         [that, and]   \n",
       " 4                  [Then]       [a, the, the]       []                  []   \n",
       " 5                      []          [the, the]       []               [but]   \n",
       " 6      [vehemently, away]                  []       []               [but]   \n",
       " 7                 [Later]            [the, a]       []             [while]   \n",
       " 8                      []          [the, the]       []               [and]   \n",
       " 9                      []                  []       []                  []   \n",
       " 10                     []               [the]       []               [and]   \n",
       " 11                     []            [a, the]       []   [that, and, lest]   \n",
       " 12                     []          [the, the]       []               [and]   \n",
       " 13                 [soon]                  []       []               [but]   \n",
       " 14     [more, thoroughly]               [the]       []              [that]   \n",
       " 15  [Suddenly, magically]               [the]       []              [that]   \n",
       " 16     [henceforth, away]               [the]       []  [and, that, while]   \n",
       " 17                     []                [no]       []               [but]   \n",
       " 18                     []          [the, the]       []              [When]   \n",
       " 19                     []          [The, the]       []               [and]   \n",
       " 20                 [Soon]  [a, the, the, the]       []               [and]   \n",
       " 21            [genuinely]                  []       []              [Upon]   \n",
       " 22         [never, again]               [the]       []          [and, and]   \n",
       " \n",
       "          POS_PART POS_NUM  ...          RE         ASF      ASM     OM RCI  \\\n",
       " 0              []      []  ...          []          []       []     []  []   \n",
       " 1              []      []  ...          []          []       []     []  []   \n",
       " 2              []      []  ...          []          []       []     []  []   \n",
       " 3            [to]      []  ...          []          []       []     []  []   \n",
       " 4              []      []  ...          []          []       []     []  []   \n",
       " 5              []      []  ...          []          []       []     []  []   \n",
       " 6   [to, not, to]      []  ...          []          []       []  [can]  []   \n",
       " 7              []      []  ...          []          []       []     []  []   \n",
       " 8              []      []  ...          []          []       []     []  []   \n",
       " 9              []      []  ...          []          []       []     []  []   \n",
       " 10           [to]      []  ...          []          []       []     []  []   \n",
       " 11             []      []  ...    [killed]          []       []     []  []   \n",
       " 12          [not]      []  ...          []          []   [does]     []  []   \n",
       " 13             []      []  ...   [furious]          []       []     []  []   \n",
       " 14             []      []  ...          []          []       []     []  []   \n",
       " 15             []      []  ...          []          []       []     []  []   \n",
       " 16             []      []  ...  [snatches]  [snatches]       []     []  []   \n",
       " 17           [to]      []  ...          []          []       []     []  []   \n",
       " 18             []      []  ...  [murdered]          []       []     []  []   \n",
       " 19       [to, to]      []  ...          []          []       []     []  []   \n",
       " 20             []      []  ...          []          []       []     []  []   \n",
       " 21             []      []  ...          []          []  [loved]     []  []   \n",
       " 22           [to]      []  ...          []          []       []     []  []   \n",
       " \n",
       "         DMC          OR                QAS  PA  PR  \n",
       " 0        []          []  [The, story, the]  []  []  \n",
       " 1        []          []    [the, business]  []  []  \n",
       " 2        []          []                 []  []  []  \n",
       " 3        []          []              [the]  []  []  \n",
       " 4        []          []         [the, the]  []  []  \n",
       " 5        []          []         [the, the]  []  []  \n",
       " 6        []          []                 []  []  []  \n",
       " 7        []          []              [the]  []  []  \n",
       " 8        []          []         [the, the]  []  []  \n",
       " 9        []          []                 []  []  []  \n",
       " 10  [blood]          []       [the, blood]  []  []  \n",
       " 11       []          []              [the]  []  []  \n",
       " 12       []          []         [the, the]  []  []  \n",
       " 13       []          []                 []  []  []  \n",
       " 14       []          []              [the]  []  []  \n",
       " 15       []          []              [the]  []  []  \n",
       " 16       []  [snatches]              [the]  []  []  \n",
       " 17       []          []                 []  []  []  \n",
       " 18       []          []         [the, the]  []  []  \n",
       " 19       []          []         [The, the]  []  []  \n",
       " 20       []          []    [the, the, the]  []  []  \n",
       " 21       []          []                 []  []  []  \n",
       " 22       []          []              [the]  []  []  \n",
       " \n",
       " [23 rows x 197 columns])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = \"testVisual/single\"\n",
    "reset_output_dir(output_dir)\n",
    "\n",
    "stylo = sm.StyloMetrix('en', debug=True, save_path=output_dir) # define langauge, one of ('de','en', 'pl', 'ru', 'ukr')\n",
    "metrics = stylo.transform(outputList) # list of texts\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19670c0d",
   "metadata": {},
   "source": [
    "#### Extracción de rasgos en múltiples registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bcfd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\spacy\\util.py:910: UserWarning: [W095] Model 'en_core_web_trf' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.2). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing index: 110956 (iteration 0)\n",
      "[OK] Total de oraciones: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/23 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 23/23 [00:03<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved in location: testVisual\\multiple\\output_iter0_idx1109561.csv\n",
      "File saved in location: testVisual\\multiple\\debug_iter0_idx1109561.csv\n",
      "Saved: output_iter0_idx110956.csv and debug_iter0_idx110956.csv\n",
      "Processing index: 363000 (iteration 1)\n",
      "[OK] Total de oraciones: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 11.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved in location: testVisual\\multiple\\output_iter1_idx3630001.csv\n",
      "File saved in location: testVisual\\multiple\\debug_iter1_idx3630001.csv\n",
      "Saved: output_iter1_idx363000.csv and debug_iter1_idx363000.csv\n",
      "Processing index: 172379 (iteration 2)\n",
      "[OK] Total de oraciones: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:02<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved in location: testVisual\\multiple\\output_iter2_idx1723791.csv\n",
      "File saved in location: testVisual\\multiple\\debug_iter2_idx1723791.csv\n",
      "Saved: output_iter2_idx172379.csv and debug_iter2_idx172379.csv\n",
      "Processing index: 200619 (iteration 3)\n",
      "[OK] Total de oraciones: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved in location: testVisual\\multiple\\output_iter3_idx2006191.csv\n",
      "File saved in location: testVisual\\multiple\\debug_iter3_idx2006191.csv\n",
      "Saved: output_iter3_idx200619.csv and debug_iter3_idx200619.csv\n",
      "Processing index: 27573 (iteration 4)\n",
      "[OK] Total de oraciones: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved in location: testVisual\\multiple\\output_iter4_idx275731.csv\n",
      "File saved in location: testVisual\\multiple\\debug_iter4_idx275731.csv\n",
      "Saved: output_iter4_idx27573.csv and debug_iter4_idx27573.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"testVisual/multiple\"\n",
    "reset_output_dir(output_dir)\n",
    "\n",
    "stylo = sm.StyloMetrix('en', debug=True, save_path=output_dir)\n",
    "\n",
    "for idx, i in enumerate(generation_sample.index):\n",
    "    print(f\"Processing index: {i} (iteration {idx})\")\n",
    "    text = generation_sample['generation'].loc[i]\n",
    "    sentences = split_text_into_sentences(text)\n",
    "    \n",
    "    # Cambiar los nombres de los archivos para cada iteración\n",
    "    stylo.output_name = f\"output_iter{idx}_idx{i}\"\n",
    "    stylo.debug_name = f\"debug_iter{idx}_idx{i}\"\n",
    "    features = stylo.transform(sentences)\n",
    "    print(f\"Saved: {stylo.output_name}.csv and {stylo.debug_name}.csv\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a2efff",
   "metadata": {},
   "source": [
    "#### Prueba de creación de DF único"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d2a320e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_dataset(df_original, sample_size=None):\n",
    "    \"\"\"\n",
    "    Extrae features estilométricos a nivel de oración.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame con estructura: id_original, model, domain, sentence_num, text, features...\n",
    "    \"\"\"\n",
    "    if sample_size:\n",
    "        df_original = df_original.sample(n=sample_size, random_state=42)\n",
    "    \n",
    "    # Inicializar StyloMetrix (sin guardar archivos)\n",
    "    stylo = sm.StyloMetrix('en', debug=False)  # debug=False para evitar archivos\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for idx, row in df_original.iterrows():\n",
    "        # Dividir en oraciones (en memoria)\n",
    "        sentences = split_text_into_sentences(row['generation'])\n",
    "        \n",
    "        # Extraer features para todas las oraciones del documento\n",
    "        features_df = stylo.transform(sentences)\n",
    "        \n",
    "        # Agregar metadatos del documento original\n",
    "        features_df.insert(0, 'id_original', row['id'])\n",
    "        features_df.insert(1, 'model', row['model'])\n",
    "        features_df.insert(2, 'domain', row['domain'])\n",
    "        features_df.insert(3, 'sentence_num', range(len(sentences)))\n",
    "        # La columna 'text' ya existe en features_df (viene de stylo.transform)\n",
    "        \n",
    "        all_results.append(features_df)\n",
    "    \n",
    "    # Concatenar todos los resultados\n",
    "    final_df = pd.concat(all_results, ignore_index=True)\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "251ed686",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\spacy\\util.py:910: UserWarning: [W095] Model 'en_core_web_trf' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.2). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/23 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "  4%|▍         | 1/23 [00:00<00:02,  8.16it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 23/23 [00:01<00:00, 12.19it/s]\n",
      "100%|██████████| 23/23 [00:01<00:00, 12.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 5/5 [00:00<00:00, 14.83it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 14.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "  5%|▌         | 1/19 [00:00<00:01,  9.66it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 19/19 [00:01<00:00,  9.64it/s]\n",
      "100%|██████████| 19/19 [00:01<00:00,  9.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 5/5 [00:00<00:00,  6.86it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      " 10%|█         | 1/10 [00:00<00:01,  6.09it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 10/10 [00:01<00:00,  5.27it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  5.27it/s]\n"
     ]
    }
   ],
   "source": [
    "features_df = extract_features_from_dataset(generation_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1b8fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (62, 201)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_original</th>\n",
       "      <th>model</th>\n",
       "      <th>domain</th>\n",
       "      <th>sentence_num</th>\n",
       "      <th>text</th>\n",
       "      <th>POS_VERB</th>\n",
       "      <th>POS_NOUN</th>\n",
       "      <th>POS_ADJ</th>\n",
       "      <th>POS_ADV</th>\n",
       "      <th>POS_DET</th>\n",
       "      <th>...</th>\n",
       "      <th>RE</th>\n",
       "      <th>ASF</th>\n",
       "      <th>ASM</th>\n",
       "      <th>OM</th>\n",
       "      <th>RCI</th>\n",
       "      <th>DMC</th>\n",
       "      <th>OR</th>\n",
       "      <th>QAS</th>\n",
       "      <th>PA</th>\n",
       "      <th>PR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c4059838-c14e-4b84-b75c-12bc0bd2f34a</td>\n",
       "      <td>cohere</td>\n",
       "      <td>books</td>\n",
       "      <td>0</td>\n",
       "      <td>The story centers on Charles, the husband of A...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c4059838-c14e-4b84-b75c-12bc0bd2f34a</td>\n",
       "      <td>cohere</td>\n",
       "      <td>books</td>\n",
       "      <td>1</td>\n",
       "      <td>He insists that she stay in the chateau while ...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c4059838-c14e-4b84-b75c-12bc0bd2f34a</td>\n",
       "      <td>cohere</td>\n",
       "      <td>books</td>\n",
       "      <td>2</td>\n",
       "      <td>Charles abruptly ends his trip and returns hom...</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c4059838-c14e-4b84-b75c-12bc0bd2f34a</td>\n",
       "      <td>cohere</td>\n",
       "      <td>books</td>\n",
       "      <td>3</td>\n",
       "      <td>He announces that he has sold the estate, and ...</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c4059838-c14e-4b84-b75c-12bc0bd2f34a</td>\n",
       "      <td>cohere</td>\n",
       "      <td>books</td>\n",
       "      <td>4</td>\n",
       "      <td>Then he hands Alice a key he says he found on ...</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4a64da9c-2df8-4f58-91ee-2f9192cc5667</td>\n",
       "      <td>mistral</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>5</td>\n",
       "      <td>The recent surge of attention to medical image...</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>4a64da9c-2df8-4f58-91ee-2f9192cc5667</td>\n",
       "      <td>mistral</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>6</td>\n",
       "      <td>Deep network architectures are particularly go...</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>4a64da9c-2df8-4f58-91ee-2f9192cc5667</td>\n",
       "      <td>mistral</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>7</td>\n",
       "      <td>Deep network training is now affordable with t...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>4a64da9c-2df8-4f58-91ee-2f9192cc5667</td>\n",
       "      <td>mistral</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>8</td>\n",
       "      <td>The emergence of self-supervised and unsupervi...</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>4a64da9c-2df8-4f58-91ee-2f9192cc5667</td>\n",
       "      <td>mistral</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>9</td>\n",
       "      <td>The promise of this research is to enable the ...</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id_original    model     domain  sentence_num  \\\n",
       "0   c4059838-c14e-4b84-b75c-12bc0bd2f34a   cohere      books             0   \n",
       "1   c4059838-c14e-4b84-b75c-12bc0bd2f34a   cohere      books             1   \n",
       "2   c4059838-c14e-4b84-b75c-12bc0bd2f34a   cohere      books             2   \n",
       "3   c4059838-c14e-4b84-b75c-12bc0bd2f34a   cohere      books             3   \n",
       "4   c4059838-c14e-4b84-b75c-12bc0bd2f34a   cohere      books             4   \n",
       "..                                   ...      ...        ...           ...   \n",
       "57  4a64da9c-2df8-4f58-91ee-2f9192cc5667  mistral  abstracts             5   \n",
       "58  4a64da9c-2df8-4f58-91ee-2f9192cc5667  mistral  abstracts             6   \n",
       "59  4a64da9c-2df8-4f58-91ee-2f9192cc5667  mistral  abstracts             7   \n",
       "60  4a64da9c-2df8-4f58-91ee-2f9192cc5667  mistral  abstracts             8   \n",
       "61  4a64da9c-2df8-4f58-91ee-2f9192cc5667  mistral  abstracts             9   \n",
       "\n",
       "                                                 text  POS_VERB  POS_NOUN  \\\n",
       "0   The story centers on Charles, the husband of A...  0.200000  0.200000   \n",
       "1   He insists that she stay in the chateau while ...  0.200000  0.133333   \n",
       "2   Charles abruptly ends his trip and returns hom...  0.300000  0.100000   \n",
       "3   He announces that he has sold the estate, and ...  0.375000  0.062500   \n",
       "4   Then he hands Alice a key he says he found on ...  0.235294  0.176471   \n",
       "..                                                ...       ...       ...   \n",
       "57  The recent surge of attention to medical image...  0.161290  0.387097   \n",
       "58  Deep network architectures are particularly go...  0.125000  0.333333   \n",
       "59  Deep network training is now affordable with t...  0.066667  0.366667   \n",
       "60  The emergence of self-supervised and unsupervi...  0.176471  0.382353   \n",
       "61  The promise of this research is to enable the ...  0.193548  0.290323   \n",
       "\n",
       "     POS_ADJ   POS_ADV   POS_DET  ...   RE  ASF  ASM        OM  RCI  DMC   OR  \\\n",
       "0   0.066667  0.000000  0.133333  ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.0   \n",
       "1   0.000000  0.000000  0.066667  ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.0   \n",
       "2   0.000000  0.200000  0.000000  ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.0   \n",
       "3   0.000000  0.062500  0.062500  ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.0   \n",
       "4   0.000000  0.058824  0.176471  ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.0   \n",
       "..       ...       ...       ...  ...  ...  ...  ...       ...  ...  ...  ...   \n",
       "57  0.096774  0.000000  0.129032  ...  0.0  0.0  0.0  0.032258  0.0  0.0  0.0   \n",
       "58  0.208333  0.125000  0.000000  ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.0   \n",
       "59  0.133333  0.033333  0.033333  ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.0   \n",
       "60  0.176471  0.029412  0.058824  ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.0   \n",
       "61  0.096774  0.000000  0.129032  ...  0.0  0.0  0.0  0.032258  0.0  0.0  0.0   \n",
       "\n",
       "         QAS   PA   PR  \n",
       "0   0.200000  0.0  0.0  \n",
       "1   0.133333  0.0  0.0  \n",
       "2   0.000000  0.0  0.0  \n",
       "3   0.062500  0.0  0.0  \n",
       "4   0.117647  0.0  0.0  \n",
       "..       ...  ...  ...  \n",
       "57  0.064516  0.0  0.0  \n",
       "58  0.000000  0.0  0.0  \n",
       "59  0.033333  0.0  0.0  \n",
       "60  0.058824  0.0  0.0  \n",
       "61  0.096774  0.0  0.0  \n",
       "\n",
       "[62 rows x 201 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Uso:\n",
    "print(f\"Shape: {features_df.shape}\")\n",
    "display(features_df.head(62))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
