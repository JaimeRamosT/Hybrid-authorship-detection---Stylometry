{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ba2cbfd",
   "metadata": {},
   "source": [
    "# Desarrollo de DF único - Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33e0364",
   "metadata": {},
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2636f4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stylo_metrix as sm\n",
    "import pandas as pd\n",
    "from raid import run_detection, run_evaluation\n",
    "from raid.utils import load_data\n",
    "\n",
    "from processer import split_text_into_sentences\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95d17c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the RAID dataset without adversarial attacks\n",
    "or_train_noadv_df = load_data(split=\"train\", include_adversarial=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8ab3cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training data shape: (467985, 11)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original training data shape: {or_train_noadv_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "206c9e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "intCols = ['id','model', 'domain', 'title', 'prompt', 'generation']\n",
    "\n",
    "# Copia del dataframe con columnas específicas\n",
    "train_noadv_df = or_train_noadv_df.copy()\n",
    "train_noadv_df = train_noadv_df[intCols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f0d8cc",
   "metadata": {},
   "source": [
    "## Versión 1 - Fusión original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c393a4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model</th>\n",
       "      <th>domain</th>\n",
       "      <th>generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>416790</th>\n",
       "      <td>d474d928-a0b4-4cff-b4c6-0ac1ea7137c3</td>\n",
       "      <td>mistral</td>\n",
       "      <td>wiki</td>\n",
       "      <td>SF Studios is a Swedish film production and di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218239</th>\n",
       "      <td>0915805f-1e28-499d-90ae-3a5ec1525fd5</td>\n",
       "      <td>mistral-chat</td>\n",
       "      <td>poetry</td>\n",
       "      <td>On this Christmas Day, as the world wakes,\\nA ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87832</th>\n",
       "      <td>6eddea46-27b0-4697-8667-82cf5444a48b</td>\n",
       "      <td>llama-chat</td>\n",
       "      <td>books</td>\n",
       "      <td>In the small town of Willowdale, a beautiful a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171835</th>\n",
       "      <td>c39958f4-2074-4be6-9c11-9bd7316cabbc</td>\n",
       "      <td>gpt3</td>\n",
       "      <td>news</td>\n",
       "      <td>\\n\\nThe Scissor Sisters have been named best l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169504</th>\n",
       "      <td>7e23796a-4fc1-4eb5-a3c6-d5e58a221d95</td>\n",
       "      <td>gpt4</td>\n",
       "      <td>news</td>\n",
       "      <td>Former England manager Kevin Keegan heaped pra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391988</th>\n",
       "      <td>b1d446fa-69e5-4126-8396-a5e4b39a7531</td>\n",
       "      <td>mistral-chat</td>\n",
       "      <td>reviews</td>\n",
       "      <td>Taken 2 is a thrilling sequel to the 2008 acti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54119</th>\n",
       "      <td>d2898250-a261-47e4-b241-61cea693826d</td>\n",
       "      <td>gpt4</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>This academic paper presents an innovative met...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382920</th>\n",
       "      <td>44f6a282-1b8a-48e1-8ebb-feb51bcf5a68</td>\n",
       "      <td>mistral</td>\n",
       "      <td>reviews</td>\n",
       "      <td>\"Midnight in Paris\" is a movie that is so good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214533</th>\n",
       "      <td>1417761b-05b6-4238-ae73-8eab757f1552</td>\n",
       "      <td>mistral</td>\n",
       "      <td>poetry</td>\n",
       "      <td>Sky at My Doorway, Sunrises and Distant Thunde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108754</th>\n",
       "      <td>35833503-8e4e-4ef4-ab7b-ace2713d080d</td>\n",
       "      <td>cohere-chat</td>\n",
       "      <td>books</td>\n",
       "      <td>The novel is about a young man named Jake who ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          id         model     domain  \\\n",
       "416790  d474d928-a0b4-4cff-b4c6-0ac1ea7137c3       mistral       wiki   \n",
       "218239  0915805f-1e28-499d-90ae-3a5ec1525fd5  mistral-chat     poetry   \n",
       "87832   6eddea46-27b0-4697-8667-82cf5444a48b    llama-chat      books   \n",
       "171835  c39958f4-2074-4be6-9c11-9bd7316cabbc          gpt3       news   \n",
       "169504  7e23796a-4fc1-4eb5-a3c6-d5e58a221d95          gpt4       news   \n",
       "...                                      ...           ...        ...   \n",
       "391988  b1d446fa-69e5-4126-8396-a5e4b39a7531  mistral-chat    reviews   \n",
       "54119   d2898250-a261-47e4-b241-61cea693826d          gpt4  abstracts   \n",
       "382920  44f6a282-1b8a-48e1-8ebb-feb51bcf5a68       mistral    reviews   \n",
       "214533  1417761b-05b6-4238-ae73-8eab757f1552       mistral     poetry   \n",
       "108754  35833503-8e4e-4ef4-ab7b-ace2713d080d   cohere-chat      books   \n",
       "\n",
       "                                               generation  \n",
       "416790  SF Studios is a Swedish film production and di...  \n",
       "218239  On this Christmas Day, as the world wakes,\\nA ...  \n",
       "87832   In the small town of Willowdale, a beautiful a...  \n",
       "171835  \\n\\nThe Scissor Sisters have been named best l...  \n",
       "169504  Former England manager Kevin Keegan heaped pra...  \n",
       "...                                                   ...  \n",
       "391988  Taken 2 is a thrilling sequel to the 2008 acti...  \n",
       "54119   This academic paper presents an innovative met...  \n",
       "382920  \"Midnight in Paris\" is a movie that is so good...  \n",
       "214533  Sky at My Doorway, Sunrises and Distant Thunde...  \n",
       "108754  The novel is about a young man named Jake who ...  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filtered_by_domain = train_noadv_df[\n",
    "    (train_noadv_df['domain'] != 'recipes')\n",
    "    ]\n",
    "generation_sample = filtered_by_domain[['id', 'model', 'domain', 'generation']].sample(n=1000, random_state=50)\n",
    "\n",
    "display(generation_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "701f0257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_dataset(df_original, sample_size=None):\n",
    "    \"\"\"\n",
    "    Extrae features estilométricos a nivel de oración.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame con estructura: id_original, model, domain, sentence_num, text, features...\n",
    "    \"\"\"\n",
    "    if sample_size:\n",
    "        df_original = df_original.sample(n=sample_size, random_state=42)\n",
    "    \n",
    "    # Inicializar StyloMetrix (sin guardar archivos)\n",
    "    stylo = sm.StyloMetrix('en', debug=False)  # debug=False para evitar archivos\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for idx, row in df_original.iterrows():\n",
    "        # Dividir en oraciones (en memoria)\n",
    "        sentences = split_text_into_sentences(row['generation'])\n",
    "        \n",
    "        # Extraer features para todas las oraciones del documento\n",
    "        features_df = stylo.transform(sentences)\n",
    "        \n",
    "        # Agregar metadatos del documento original\n",
    "        features_df.insert(0, 'id_original', row['id'])\n",
    "        features_df.insert(1, 'model', row['model'])\n",
    "        features_df.insert(2, 'domain', row['domain'])\n",
    "        features_df.insert(3, 'sentence_num', range(len(sentences)))\n",
    "        # La columna 'text' ya existe en features_df (viene de stylo.transform)\n",
    "        \n",
    "        all_results.append(features_df)\n",
    "    \n",
    "    # Concatenar todos los resultados\n",
    "    final_df = pd.concat(all_results, ignore_index=True)\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c9c4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\spacy\\util.py:910: UserWarning: [W095] Model 'en_core_web_trf' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.2). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/22 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 22/22 [00:02<00:00,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 12/12 [00:01<00:00,  7.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 16/16 [00:02<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 5/5 [00:00<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 17/17 [00:02<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 3/3 [00:00<00:00,  9.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 6/6 [00:00<00:00,  9.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 11/11 [00:01<00:00,  9.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 7/7 [00:00<00:00,  9.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 13/13 [00:01<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 6/6 [00:00<00:00,  7.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 12/12 [00:01<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 11/11 [00:01<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 8/8 [00:01<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 4/4 [00:00<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 11/11 [00:01<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 25/25 [00:03<00:00,  8.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 16/16 [00:01<00:00,  8.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 18/18 [00:03<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 7/7 [00:03<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 13/13 [00:02<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 7/7 [00:01<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 18/18 [00:03<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 11/11 [00:02<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float division by zero\n",
      " AT METRIC ST_HERDAN_TTR, TEXT: She...\n",
      "[OK] Total de oraciones: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 7/7 [00:01<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 16/16 [00:03<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 18/18 [00:02<00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 7/7 [00:01<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 14/14 [00:01<00:00,  8.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 13/13 [00:02<00:00,  5.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 6/6 [00:01<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 15/15 [00:02<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 11/11 [00:02<00:00,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 7/7 [00:01<00:00,  5.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 7/7 [00:01<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 10/10 [00:02<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 15/15 [00:04<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 6/6 [00:01<00:00,  5.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 16/16 [00:02<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 14/14 [00:01<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 11/11 [00:01<00:00,  5.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 9/9 [00:01<00:00,  7.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 14/14 [00:01<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 11/11 [00:01<00:00, 10.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 11/11 [00:02<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/23 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 23/23 [00:04<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/26 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 26/26 [00:05<00:00,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 7/7 [00:02<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 10/10 [00:02<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 13/13 [00:02<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 13/13 [00:02<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 5/5 [00:02<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 19/19 [00:03<00:00,  5.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 11/11 [00:01<00:00,  7.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 8/8 [00:01<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 4/4 [00:00<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 7/7 [00:01<00:00,  4.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 21/21 [00:03<00:00,  6.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 8/8 [00:01<00:00,  7.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 10/10 [00:01<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 25/25 [00:03<00:00,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 6/6 [00:00<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 20/20 [00:02<00:00,  8.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 7/7 [00:01<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 15/15 [00:02<00:00,  5.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 8/8 [00:01<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/43 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 43/43 [00:04<00:00,  9.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 31/31 [00:03<00:00,  7.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 12/12 [00:01<00:00,  7.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 14/14 [00:01<00:00,  8.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 20/20 [00:02<00:00,  9.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 13/13 [00:02<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 16/16 [00:02<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 28/28 [00:03<00:00,  8.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 5/5 [00:00<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 7/7 [00:01<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 27/27 [00:05<00:00,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 6/6 [00:01<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 16/16 [00:02<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 19/19 [00:03<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 17/17 [00:02<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 9/9 [00:01<00:00,  4.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 27/27 [00:04<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 16/16 [00:04<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 7/7 [00:02<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 4/4 [00:00<00:00,  6.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      " 67%|██████▋   | 2/3 [00:00<00:00,  2.49it/s]"
     ]
    }
   ],
   "source": [
    "features_df = extract_features_from_dataset(generation_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc130df",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Uso:\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mfeatures_df\u001b[49m.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m display(features_df.head(\u001b[32m5\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name 'features_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Uso:\n",
    "print(f\"Shape: {features_df.shape}\")\n",
    "display(features_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7538dd9",
   "metadata": {},
   "source": [
    "## Versión 2 - Tags codificados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8c06b4",
   "metadata": {},
   "source": [
    "### Codificación de etiquetas 'model' y 'domain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a825060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información del dataset original:\n",
      "Forma del dataset: (467985, 11)\n",
      "Columnas: ['id', 'adv_source_id', 'source_id', 'model', 'decoding', 'repetition_penalty', 'attack', 'domain', 'title', 'prompt', 'generation']\n",
      "Modelos unicos: ['human' 'llama-chat' 'mpt' 'mpt-chat' 'gpt2' 'mistral' 'mistral-chat'\n",
      " 'gpt3' 'cohere' 'chatgpt' 'gpt4' 'cohere-chat']\n",
      "Dominios unicos: ['abstracts' 'books' 'news' 'poetry' 'recipes' 'reddit' 'reviews' 'wiki']\n"
     ]
    }
   ],
   "source": [
    "print(\"Información del dataset original:\")\n",
    "print(f\"Forma del dataset: {or_train_noadv_df.shape}\")\n",
    "print(f\"Columnas: {list(or_train_noadv_df.columns)}\")\n",
    "print(f\"Modelos unicos: {or_train_noadv_df['model'].unique()}\")\n",
    "print(f\"Dominios unicos: {or_train_noadv_df['domain'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ace907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información del dataset generado:\n",
      "Forma del dataset: (10036, 201)\n",
      "Columnas: ['id_original', 'model', 'domain', 'sentence_num', 'text', 'POS_VERB', 'POS_NOUN', 'POS_ADJ', 'POS_ADV', 'POS_DET', 'POS_INTJ', 'POS_CONJ', 'POS_PART', 'POS_NUM', 'POS_PREP', 'POS_PRO', 'L_REF', 'L_HASHTAG', 'L_MENTION', 'L_RT', 'L_LINKS', 'L_CONT_A', 'L_FUNC_A', 'L_CONT_T', 'L_FUNC_T', 'L_PLURAL_NOUNS', 'L_SINGULAR_NOUNS', 'L_PROPER_NAME', 'L_PERSONAL_NAME', 'L_NOUN_PHRASES', 'L_PUNCT', 'L_PUNCT_DOT', 'L_PUNCT_COM', 'L_PUNCT_SEMC', 'L_PUNCT_COL', 'L_PUNCT_DASH', 'L_POSSESSIVES', 'L_ADJ_POSITIVE', 'L_ADJ_COMPARATIVE', 'L_ADJ_SUPERLATIVE', 'L_ADV_POSITIVE', 'L_ADV_COMPARATIVE', 'L_ADV_SUPERLATIVE', 'PS_CONTRADICTION', 'PS_AGREEMENT', 'PS_EXAMPLES', 'PS_CONSEQUENCE', 'PS_CAUSE', 'PS_LOCATION', 'PS_TIME', 'PS_CONDITION', 'PS_MANNER', 'SY_QUESTION', 'SY_NARRATIVE', 'SY_NEGATIVE_QUESTIONS', 'SY_SPECIAL_QUESTIONS', 'SY_TAG_QUESTIONS', 'SY_GENERAL_QUESTIONS', 'SY_EXCLAMATION', 'SY_IMPERATIVE', 'SY_SUBORD_SENT', 'SY_SUBORD_SENT_PUNCT', 'SY_COORD_SENT', 'SY_COORD_SENT_PUNCT', 'SY_SIMPLE_SENT', 'SY_INVERSE_PATTERNS', 'SY_SIMILE', 'SY_FRONTING', 'SY_IRRITATION', 'SY_INTENSIFIER', 'SY_QUOT', 'VT_PRESENT_SIMPLE', 'VT_PRESENT_PROGRESSIVE', 'VT_PRESENT_PERFECT', 'VT_PRESENT_PERFECT_PROGR', 'VT_PRESENT_SIMPLE_PASSIVE', 'VT_PRESENT_PROGR_PASSIVE', 'VT_PRESENT_PERFECT_PASSIVE', 'VT_PAST_SIMPLE', 'VT_PAST_SIMPLE_BE', 'VT_PAST_PROGR', 'VT_PAST_PERFECT', 'VT_PAST_PERFECT_PROGR', 'VT_PAST_SIMPLE_PASSIVE', 'VT_PAST_POGR_PASSIVE', 'VT_PAST_PERFECT_PASSIVE', 'VT_FUTURE_SIMPLE', 'VT_FUTURE_PROGRESSIVE', 'VT_FUTURE_PERFECT', 'VT_FUTURE_PERFECT_PROGR', 'VT_FUTURE_SIMPLE_PASSIVE', 'VT_FUTURE_PROGR_PASSIVE', 'VT_FUTURE_PERFECT_PASSIVE', 'VT_WOULD', 'VT_WOULD_PASSIVE', 'VT_WOULD_PROGRESSIVE', 'VT_WOULD_PERFECT', 'VT_WOULD_PERFECT_PASSIVE', 'VT_SHOULD', 'VT_SHOULD_PASSIVE', 'VT_SHALL', 'VT_SHALL_PASSIVE', 'VT_SHOULD_PROGRESSIVE', 'VT_SHOULD_PERFECT', 'VT_SHOULD_PERFECT_PASSIVE', 'VT_MUST', 'VT_MUST_PASSIVE', 'VT_MUST_PROGRESSIVE', 'VT_MUST_PERFECT', 'VT_MST_PERFECT_PASSIVE', 'VT_CAN', 'VT_CAN_PASSIVE', 'VT_COULD', 'VT_COULD_PASSIVE', 'VT_CAN_PROGRESSIVE', 'VT_COULD_PROGRESSIVE', 'VT_COULD_PERFECT', 'VT_COULD_PERFECT_PASSIVE', 'VT_MAY', 'VT_MAY_PASSIVE', 'VT_MIGHT', 'VT_MIGHT_PASSIVE', 'VT_MAY_PROGRESSIVE', 'VT_MIGTH_PERFECT', 'VT_MIGHT_PERFECT_PASSIVE', 'VT_MAY_PERFECT_PASSIVE', 'ST_TYPE_TOKEN_RATIO_LEMMAS', 'ST_HERDAN_TTR', 'ST_MASS_TTR', 'ST_SENT_WRDSPERSENT', 'ST_SENT_DIFFERENCE', 'ST_REPETITIONS_WORDS', 'ST_REPETITIONS_SENT', 'ST_SENT_D_VP', 'ST_SENT_D_NP', 'ST_SENT_D_PP', 'ST_SENT_D_ADJP', 'ST_SENT_D_ADVP', 'L_I_PRON', 'L_HE_PRON', 'L_SHE_PRON', 'L_IT_PRON', 'L_YOU_PRON', 'L_WE_PRON', 'L_THEY_PRON', 'L_ME_PRON', 'L_YOU_OBJ_PRON', 'L_HIM_PRON', 'L_HER_OBJECT_PRON', 'L_IT_OBJECT_PRON', 'L_US_PRON', 'L_THEM_PRON', 'L_MY_PRON', 'L_YOUR_PRON', 'L_HIS_PRON', 'L_HER_PRON', 'L_ITS_PRON', 'L_OUR_PRON', 'L_THEIR_PRON', 'L_YOURS_PRON', 'L_THEIRS_PRON', 'L_HERS_PRON', 'L_OURS_PRON', 'L_MYSELF_PRON', 'L_YOURSELF_PRON', 'L_HIMSELF_PRON', 'L_HERSELF_PRON', 'L_ITSELF_PRON', 'L_OURSELVES_PRON', 'L_YOURSELVES_PRON', 'L_THEMSELVES_PRON', 'L_FIRST_PERSON_SING_PRON', 'L_SECOND_PERSON_PRON', 'L_THIRD_PERSON_SING_PRON', 'L_THIRD_PERSON_PLURAL_PRON', 'VF_INFINITIVE', 'G_PASSIVE', 'G_ACTIVE', 'G_PRESENT', 'G_PAST', 'G_FUTURE', 'G_MODALS_SIMPLE', 'G_MODALS_CONT', 'G_MODALS_PERFECT', 'AN', 'DDP', 'SVP', 'CDS', 'DDF', 'IS', 'PS', 'RE', 'ASF', 'ASM', 'OM', 'RCI', 'DMC', 'OR', 'QAS', 'PA', 'PR']\n",
      "Modelos unicos: ['mistral' 'mistral-chat' 'llama-chat' 'gpt3' 'gpt4' 'cohere'\n",
      " 'cohere-chat' 'gpt2' 'mpt-chat' 'human' 'mpt' 'chatgpt']\n",
      "Dominios unicos: ['wiki' 'poetry' 'books' 'news' 'abstracts' 'reddit' 'reviews']\n"
     ]
    }
   ],
   "source": [
    "print(\"Información del dataset generado:\")\n",
    "print(f\"Forma del dataset: {features_df.shape}\")\n",
    "print(f\"Columnas: {list(features_df.columns)}\")\n",
    "print(f\"Modelos unicos: {features_df['model'].unique()}\")\n",
    "print(f\"Dominios unicos: {features_df['domain'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d63f649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificación de etiquetas 'model' y 'domain'\n",
    "id_encoder = LabelEncoder()\n",
    "model_encoder = LabelEncoder()\n",
    "domain_encoder = LabelEncoder()\n",
    "features_df['id_encoded'] = id_encoder.fit_transform(features_df['id_original'])\n",
    "features_df['model_encoded'] = model_encoder.fit_transform(features_df['model'])\n",
    "features_df['domain_encoded'] = domain_encoder.fit_transform(features_df['domain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7c9480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiquetas codificadas:\n",
      "Modelos:\n",
      "0: chatgpt\n",
      "1: cohere\n",
      "2: cohere-chat\n",
      "3: gpt2\n",
      "4: gpt3\n",
      "5: gpt4\n",
      "6: human\n",
      "7: llama-chat\n",
      "8: mistral\n",
      "9: mistral-chat\n",
      "10: mpt\n",
      "11: mpt-chat\n",
      "\n",
      "Dominios:\n",
      "0: abstracts\n",
      "1: books\n",
      "2: news\n",
      "3: poetry\n",
      "4: reddit\n",
      "5: reviews\n",
      "6: wiki\n"
     ]
    }
   ],
   "source": [
    "print(\"Etiquetas codificadas:\")\n",
    "\n",
    "print(f\"Modelos:\")\n",
    "\n",
    "for i in range(len(model_encoder.classes_)):\n",
    "    print(f\"{i}: {model_encoder.classes_[i]}\")\n",
    "print()\n",
    "\n",
    "print(f\"Dominios:\")\n",
    "for i in range(len(domain_encoder.classes_)):\n",
    "    print(f\"{i}: {domain_encoder.classes_[i]}\")\n",
    "# print(f\"Modelos: {list(model_encoder.classes_)}\")\n",
    "# print(f\"Dominios: {list(domain_encoder.classes_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f87f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_original</th>\n",
       "      <th>sentence_num</th>\n",
       "      <th>model</th>\n",
       "      <th>domain</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2782</th>\n",
       "      <td>1c7df1ce-03c0-4e51-8b78-453f3f3f065b</td>\n",
       "      <td>2</td>\n",
       "      <td>llama-chat</td>\n",
       "      <td>poetry</td>\n",
       "      <td>He jokes and laughs, and makes us feel at ease, With him around, work is a breeze.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>fc475e41-678b-4334-a926-70206344ecea</td>\n",
       "      <td>0</td>\n",
       "      <td>llama-chat</td>\n",
       "      <td>poetry</td>\n",
       "      <td>Once, I thought happiness was a destination, A place I could reach and settle in, A feeling that would stay and never fade, A constant state of being, a permanent shade.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7280</th>\n",
       "      <td>96915885-996d-407c-bab7-f5ccfdb669b7</td>\n",
       "      <td>0</td>\n",
       "      <td>llama-chat</td>\n",
       "      <td>poetry</td>\n",
       "      <td>In the depths of a sunset's golden glow, Where the sky and earth meet, and the world slows, There lies a beauty, a truth profound, A moment that takes the breath, and grounds.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3241</th>\n",
       "      <td>f08102e8-63cb-40b1-bd7a-1b198565a2c0</td>\n",
       "      <td>4</td>\n",
       "      <td>human</td>\n",
       "      <td>poetry</td>\n",
       "      <td>He’s at work in the darkest night; for God is for you that guiding light.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1ef57226-f2b8-4346-8929-f516ac1d3feb</td>\n",
       "      <td>10</td>\n",
       "      <td>mpt</td>\n",
       "      <td>poetry</td>\n",
       "      <td>That it's like you get a feeling that's indescribable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9695</th>\n",
       "      <td>8616fea2-d677-4dac-b964-e448018c0d64</td>\n",
       "      <td>1</td>\n",
       "      <td>mistral</td>\n",
       "      <td>poetry</td>\n",
       "      <td>It would be so dull!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>cb9fbec9-b613-48a4-9a18-dc44cc374761</td>\n",
       "      <td>2</td>\n",
       "      <td>mpt-chat</td>\n",
       "      <td>poetry</td>\n",
       "      <td>In this haven, the heart beats true, A symphony of love's sweet dew, The lips that once whispered sweet nothings, Now speak the language of love's offerings.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>fe958001-600c-4073-8f7e-c04381999db4</td>\n",
       "      <td>8</td>\n",
       "      <td>mistral</td>\n",
       "      <td>poetry</td>\n",
       "      <td>Sis, it’s that for rightly it behoves you, That thou shouldst show me your hand.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7513</th>\n",
       "      <td>7c3e7f91-268e-445a-8c7c-e5e2e90d54bd</td>\n",
       "      <td>6</td>\n",
       "      <td>mpt-chat</td>\n",
       "      <td>poetry</td>\n",
       "      <td>Such quest demands more than fair visage graced By Cupid ’s arrow dipped within Venus ‘ embrace.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9801</th>\n",
       "      <td>f860be98-d71d-478c-9483-8a3fb2192c4f</td>\n",
       "      <td>0</td>\n",
       "      <td>llama-chat</td>\n",
       "      <td>poetry</td>\n",
       "      <td>Sure!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id_original  sentence_num       model  domain  \\\n",
       "2782  1c7df1ce-03c0-4e51-8b78-453f3f3f065b             2  llama-chat  poetry   \n",
       "2375  fc475e41-678b-4334-a926-70206344ecea             0  llama-chat  poetry   \n",
       "7280  96915885-996d-407c-bab7-f5ccfdb669b7             0  llama-chat  poetry   \n",
       "3241  f08102e8-63cb-40b1-bd7a-1b198565a2c0             4       human  poetry   \n",
       "184   1ef57226-f2b8-4346-8929-f516ac1d3feb            10         mpt  poetry   \n",
       "9695  8616fea2-d677-4dac-b964-e448018c0d64             1     mistral  poetry   \n",
       "809   cb9fbec9-b613-48a4-9a18-dc44cc374761             2    mpt-chat  poetry   \n",
       "4993  fe958001-600c-4073-8f7e-c04381999db4             8     mistral  poetry   \n",
       "7513  7c3e7f91-268e-445a-8c7c-e5e2e90d54bd             6    mpt-chat  poetry   \n",
       "9801  f860be98-d71d-478c-9483-8a3fb2192c4f             0  llama-chat  poetry   \n",
       "\n",
       "                                                                                                                                                                                 text  \n",
       "2782                                                                                               He jokes and laughs, and makes us feel at ease, With him around, work is a breeze.  \n",
       "2375        Once, I thought happiness was a destination, A place I could reach and settle in, A feeling that would stay and never fade, A constant state of being, a permanent shade.  \n",
       "7280  In the depths of a sunset's golden glow, Where the sky and earth meet, and the world slows, There lies a beauty, a truth profound, A moment that takes the breath, and grounds.  \n",
       "3241                                                                                                        He’s at work in the darkest night; for God is for you that guiding light.  \n",
       "184                                                                                                                            That it's like you get a feeling that's indescribable.  \n",
       "9695                                                                                                                                                             It would be so dull!  \n",
       "809                     In this haven, the heart beats true, A symphony of love's sweet dew, The lips that once whispered sweet nothings, Now speak the language of love's offerings.  \n",
       "4993                                                                                                 Sis, it’s that for rightly it behoves you, That thou shouldst show me your hand.  \n",
       "7513                                                                                 Such quest demands more than fair visage graced By Cupid ’s arrow dipped within Venus ‘ embrace.  \n",
       "9801                                                                                                                                                                            Sure!  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizar texto de registros aleatorios de dominio poetry\n",
    "pd.set_option('display.max_colwidth', None)  # Sin límite de ancho\n",
    "pd.set_option('display.max_rows', None)      # Sin límite de filas (usar con cuidado)\n",
    "\n",
    "poetry_df = features_df[features_df['domain'] == 'poetry']\n",
    "display(poetry_df[['id_original', 'sentence_num', 'model', 'domain', 'text']].sample(n=10, random_state=11))\n",
    "# 2 7 \n",
    "pd.reset_option('display.max_colwidth')\n",
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999f9507",
   "metadata": {},
   "source": [
    "### Armado de DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553e30e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar DF final\n",
    "train_df = features_df.copy()\n",
    "\n",
    "# trainCols = ['id_encoded', 'sentence_num', 'model_encoded', 'domain_encoded', 'POS_VERB', 'POS_NOUN', 'POS_ADJ', 'POS_ADV', 'POS_DET', 'POS_INTJ', 'POS_CONJ', 'POS_PART', 'POS_NUM', 'POS_PREP', 'POS_PRO', 'L_REF', 'L_HASHTAG', 'L_MENTION', 'L_RT', 'L_LINKS', 'L_CONT_A', 'L_FUNC_A', 'L_CONT_T', 'L_FUNC_T', 'L_PLURAL_NOUNS', 'L_SINGULAR_NOUNS', 'L_PROPER_NAME', 'L_PERSONAL_NAME', 'L_NOUN_PHRASES', 'L_PUNCT', 'L_PUNCT_DOT', 'L_PUNCT_COM', 'L_PUNCT_SEMC', 'L_PUNCT_COL', 'L_PUNCT_DASH', 'L_POSSESSIVES', 'L_ADJ_POSITIVE', 'L_ADJ_COMPARATIVE', 'L_ADJ_SUPERLATIVE', 'L_ADV_POSITIVE', 'L_ADV_COMPARATIVE', 'L_ADV_SUPERLATIVE', 'PS_CONTRADICTION', 'PS_AGREEMENT', 'PS_EXAMPLES', 'PS_CONSEQUENCE', 'PS_CAUSE', 'PS_LOCATION', 'PS_TIME', 'PS_CONDITION', 'PS_MANNER', 'SY_QUESTION', 'SY_NARRATIVE', 'SY_NEGATIVE_QUESTIONS', 'SY_SPECIAL_QUESTIONS', 'SY_TAG_QUESTIONS', 'SY_GENERAL_QUESTIONS', 'SY_EXCLAMATION', 'SY_IMPERATIVE', 'SY_SUBORD_SENT', 'SY_SUBORD_SENT_PUNCT', 'SY_COORD_SENT', 'SY_COORD_SENT_PUNCT', 'SY_SIMPLE_SENT', 'SY_INVERSE_PATTERNS', 'SY_SIMILE', 'SY_FRONTING', 'SY_IRRITATION', 'SY_INTENSIFIER', 'SY_QUOT', 'VT_PRESENT_SIMPLE', 'VT_PRESENT_PROGRESSIVE', 'VT_PRESENT_PERFECT', 'VT_PRESENT_PERFECT_PROGR', 'VT_PRESENT_SIMPLE_PASSIVE', 'VT_PRESENT_PROGR_PASSIVE', 'VT_PRESENT_PERFECT_PASSIVE', 'VT_PAST_SIMPLE', 'VT_PAST_SIMPLE_BE', 'VT_PAST_PROGR', 'VT_PAST_PERFECT', 'VT_PAST_PERFECT_PROGR', 'VT_PAST_SIMPLE_PASSIVE', 'VT_PAST_POGR_PASSIVE', 'VT_PAST_PERFECT_PASSIVE', 'VT_FUTURE_SIMPLE', 'VT_FUTURE_PROGRESSIVE', 'VT_FUTURE_PERFECT', 'VT_FUTURE_PERFECT_PROGR', 'VT_FUTURE_SIMPLE_PASSIVE', 'VT_FUTURE_PROGR_PASSIVE', 'VT_FUTURE_PERFECT_PASSIVE', 'VT_WOULD', 'VT_WOULD_PASSIVE', 'VT_WOULD_PROGRESSIVE', 'VT_WOULD_PERFECT', 'VT_WOULD_PERFECT_PASSIVE', 'VT_SHOULD', 'VT_SHOULD_PASSIVE', 'VT_SHALL', 'VT_SHALL_PASSIVE', 'VT_SHOULD_PROGRESSIVE', 'VT_SHOULD_PERFECT', 'VT_SHOULD_PERFECT_PASSIVE', 'VT_MUST', 'VT_MUST_PASSIVE', 'VT_MUST_PROGRESSIVE', 'VT_MUST_PERFECT', 'VT_MST_PERFECT_PASSIVE', 'VT_CAN', 'VT_CAN_PASSIVE', 'VT_COULD', 'VT_COULD_PASSIVE', 'VT_CAN_PROGRESSIVE', 'VT_COULD_PROGRESSIVE', 'VT_COULD_PERFECT', 'VT_COULD_PERFECT_PASSIVE', 'VT_MAY', 'VT_MAY_PASSIVE', 'VT_MIGHT', 'VT_MIGHT_PASSIVE', 'VT_MAY_PROGRESSIVE', 'VT_MIGTH_PERFECT', 'VT_MIGHT_PERFECT_PASSIVE', 'VT_MAY_PERFECT_PASSIVE', 'ST_TYPE_TOKEN_RATIO_LEMMAS', 'ST_HERDAN_TTR', 'ST_MASS_TTR', 'ST_SENT_WRDSPERSENT', 'ST_SENT_DIFFERENCE', 'ST_REPETITIONS_WORDS', 'ST_REPETITIONS_SENT', 'ST_SENT_D_VP', 'ST_SENT_D_NP', 'ST_SENT_D_PP', 'ST_SENT_D_ADJP', 'ST_SENT_D_ADVP', 'L_I_PRON', 'L_HE_PRON', 'L_SHE_PRON', 'L_IT_PRON', 'L_YOU_PRON', 'L_WE_PRON', 'L_THEY_PRON', 'L_ME_PRON', 'L_YOU_OBJ_PRON', 'L_HIM_PRON', 'L_HER_OBJECT_PRON', 'L_IT_OBJECT_PRON', 'L_US_PRON', 'L_THEM_PRON', 'L_MY_PRON', 'L_YOUR_PRON', 'L_HIS_PRON', 'L_HER_PRON', 'L_ITS_PRON', 'L_OUR_PRON', 'L_THEIR_PRON', 'L_YOURS_PRON', 'L_THEIRS_PRON', 'L_HERS_PRON', 'L_OURS_PRON', 'L_MYSELF_PRON', 'L_YOURSELF_PRON', 'L_HIMSELF_PRON', 'L_HERSELF_PRON', 'L_ITSELF_PRON', 'L_OURSELVES_PRON', 'L_YOURSELVES_PRON', 'L_THEMSELVES_PRON', 'L_FIRST_PERSON_SING_PRON', 'L_SECOND_PERSON_PRON', 'L_THIRD_PERSON_SING_PRON', 'L_THIRD_PERSON_PLURAL_PRON', 'VF_INFINITIVE', 'G_PASSIVE', 'G_ACTIVE', 'G_PRESENT', 'G_PAST', 'G_FUTURE', 'G_MODALS_SIMPLE', 'G_MODALS_CONT', 'G_MODALS_PERFECT', 'AN', 'DDP', 'SVP', 'CDS', 'DDF', 'IS', 'PS', 'RE', 'ASF', 'ASM', 'OM', 'RCI', 'DMC', 'OR', 'QAS', 'PA', 'PR']\n",
    "\n",
    "trainCols = ['id_encoded', 'sentence_num', 'model', 'domain', 'POS_VERB', 'POS_NOUN', 'POS_ADJ', 'POS_ADV', 'POS_DET', 'POS_INTJ', 'POS_CONJ', 'POS_PART', 'POS_NUM', 'POS_PREP', 'POS_PRO', 'L_REF', 'L_HASHTAG', 'L_MENTION', 'L_RT', 'L_LINKS', 'L_CONT_A', 'L_FUNC_A', 'L_CONT_T', 'L_FUNC_T', 'L_PLURAL_NOUNS', 'L_SINGULAR_NOUNS', 'L_PROPER_NAME', 'L_PERSONAL_NAME', 'L_NOUN_PHRASES', 'L_PUNCT', 'L_PUNCT_DOT', 'L_PUNCT_COM', 'L_PUNCT_SEMC', 'L_PUNCT_COL', 'L_PUNCT_DASH', 'L_POSSESSIVES', 'L_ADJ_POSITIVE', 'L_ADJ_COMPARATIVE', 'L_ADJ_SUPERLATIVE', 'L_ADV_POSITIVE', 'L_ADV_COMPARATIVE', 'L_ADV_SUPERLATIVE', 'PS_CONTRADICTION', 'PS_AGREEMENT', 'PS_EXAMPLES', 'PS_CONSEQUENCE', 'PS_CAUSE', 'PS_LOCATION', 'PS_TIME', 'PS_CONDITION', 'PS_MANNER', 'SY_QUESTION', 'SY_NARRATIVE', 'SY_NEGATIVE_QUESTIONS', 'SY_SPECIAL_QUESTIONS', 'SY_TAG_QUESTIONS', 'SY_GENERAL_QUESTIONS', 'SY_EXCLAMATION', 'SY_IMPERATIVE', 'SY_SUBORD_SENT', 'SY_SUBORD_SENT_PUNCT', 'SY_COORD_SENT', 'SY_COORD_SENT_PUNCT', 'SY_SIMPLE_SENT', 'SY_INVERSE_PATTERNS', 'SY_SIMILE', 'SY_FRONTING', 'SY_IRRITATION', 'SY_INTENSIFIER', 'SY_QUOT', 'VT_PRESENT_SIMPLE', 'VT_PRESENT_PROGRESSIVE', 'VT_PRESENT_PERFECT', 'VT_PRESENT_PERFECT_PROGR', 'VT_PRESENT_SIMPLE_PASSIVE', 'VT_PRESENT_PROGR_PASSIVE', 'VT_PRESENT_PERFECT_PASSIVE', 'VT_PAST_SIMPLE', 'VT_PAST_SIMPLE_BE', 'VT_PAST_PROGR', 'VT_PAST_PERFECT', 'VT_PAST_PERFECT_PROGR', 'VT_PAST_SIMPLE_PASSIVE', 'VT_PAST_POGR_PASSIVE', 'VT_PAST_PERFECT_PASSIVE', 'VT_FUTURE_SIMPLE', 'VT_FUTURE_PROGRESSIVE', 'VT_FUTURE_PERFECT', 'VT_FUTURE_PERFECT_PROGR', 'VT_FUTURE_SIMPLE_PASSIVE', 'VT_FUTURE_PROGR_PASSIVE', 'VT_FUTURE_PERFECT_PASSIVE', 'VT_WOULD', 'VT_WOULD_PASSIVE', 'VT_WOULD_PROGRESSIVE', 'VT_WOULD_PERFECT', 'VT_WOULD_PERFECT_PASSIVE', 'VT_SHOULD', 'VT_SHOULD_PASSIVE', 'VT_SHALL', 'VT_SHALL_PASSIVE', 'VT_SHOULD_PROGRESSIVE', 'VT_SHOULD_PERFECT', 'VT_SHOULD_PERFECT_PASSIVE', 'VT_MUST', 'VT_MUST_PASSIVE', 'VT_MUST_PROGRESSIVE', 'VT_MUST_PERFECT', 'VT_MST_PERFECT_PASSIVE', 'VT_CAN', 'VT_CAN_PASSIVE', 'VT_COULD', 'VT_COULD_PASSIVE', 'VT_CAN_PROGRESSIVE', 'VT_COULD_PROGRESSIVE', 'VT_COULD_PERFECT', 'VT_COULD_PERFECT_PASSIVE', 'VT_MAY', 'VT_MAY_PASSIVE', 'VT_MIGHT', 'VT_MIGHT_PASSIVE', 'VT_MAY_PROGRESSIVE', 'VT_MIGTH_PERFECT', 'VT_MIGHT_PERFECT_PASSIVE', 'VT_MAY_PERFECT_PASSIVE', 'ST_TYPE_TOKEN_RATIO_LEMMAS', 'ST_HERDAN_TTR', 'ST_MASS_TTR', 'ST_SENT_WRDSPERSENT', 'ST_SENT_DIFFERENCE', 'ST_REPETITIONS_WORDS', 'ST_REPETITIONS_SENT', 'ST_SENT_D_VP', 'ST_SENT_D_NP', 'ST_SENT_D_PP', 'ST_SENT_D_ADJP', 'ST_SENT_D_ADVP', 'L_I_PRON', 'L_HE_PRON', 'L_SHE_PRON', 'L_IT_PRON', 'L_YOU_PRON', 'L_WE_PRON', 'L_THEY_PRON', 'L_ME_PRON', 'L_YOU_OBJ_PRON', 'L_HIM_PRON', 'L_HER_OBJECT_PRON', 'L_IT_OBJECT_PRON', 'L_US_PRON', 'L_THEM_PRON', 'L_MY_PRON', 'L_YOUR_PRON', 'L_HIS_PRON', 'L_HER_PRON', 'L_ITS_PRON', 'L_OUR_PRON', 'L_THEIR_PRON', 'L_YOURS_PRON', 'L_THEIRS_PRON', 'L_HERS_PRON', 'L_OURS_PRON', 'L_MYSELF_PRON', 'L_YOURSELF_PRON', 'L_HIMSELF_PRON', 'L_HERSELF_PRON', 'L_ITSELF_PRON', 'L_OURSELVES_PRON', 'L_YOURSELVES_PRON', 'L_THEMSELVES_PRON', 'L_FIRST_PERSON_SING_PRON', 'L_SECOND_PERSON_PRON', 'L_THIRD_PERSON_SING_PRON', 'L_THIRD_PERSON_PLURAL_PRON', 'VF_INFINITIVE', 'G_PASSIVE', 'G_ACTIVE', 'G_PRESENT', 'G_PAST', 'G_FUTURE', 'G_MODALS_SIMPLE', 'G_MODALS_CONT', 'G_MODALS_PERFECT', 'AN', 'DDP', 'SVP', 'CDS', 'DDF', 'IS', 'PS', 'RE', 'ASF', 'ASM', 'OM', 'RCI', 'DMC', 'OR', 'QAS', 'PA', 'PR']\n",
    "\n",
    "# trainCols = ['id_original', 'id_encoded', 'sentence_num', 'model_encoded', 'domain_encoded', 'text']\n",
    "\n",
    "train_df = train_df[trainCols]\n",
    "\n",
    "train_df = train_df.rename(columns={\n",
    "    'id_encoded': 'id',\n",
    "    # 'model_encoded': 'model_label',\n",
    "    # 'domain_encoded': 'domain_label'\n",
    "})\n",
    "\n",
    "train_df = train_df.sort_values(by=['id', 'sentence_num']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d323249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence_num</th>\n",
       "      <th>model</th>\n",
       "      <th>domain</th>\n",
       "      <th>POS_VERB</th>\n",
       "      <th>POS_NOUN</th>\n",
       "      <th>POS_ADJ</th>\n",
       "      <th>POS_ADV</th>\n",
       "      <th>POS_DET</th>\n",
       "      <th>POS_INTJ</th>\n",
       "      <th>...</th>\n",
       "      <th>RE</th>\n",
       "      <th>ASF</th>\n",
       "      <th>ASM</th>\n",
       "      <th>OM</th>\n",
       "      <th>RCI</th>\n",
       "      <th>DMC</th>\n",
       "      <th>OR</th>\n",
       "      <th>QAS</th>\n",
       "      <th>PA</th>\n",
       "      <th>PR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mistral</td>\n",
       "      <td>books</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>mistral</td>\n",
       "      <td>books</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>mistral</td>\n",
       "      <td>books</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>mistral</td>\n",
       "      <td>books</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>mistral</td>\n",
       "      <td>books</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  sentence_num    model domain  POS_VERB  POS_NOUN   POS_ADJ   POS_ADV  \\\n",
       "0   0             0  mistral  books  0.121212  0.212121  0.060606  0.090909   \n",
       "1   0             1  mistral  books  0.240000  0.160000  0.120000  0.040000   \n",
       "2   0             2  mistral  books  0.222222  0.111111  0.111111  0.000000   \n",
       "3   0             3  mistral  books  0.285714  0.190476  0.047619  0.000000   \n",
       "4   0             4  mistral  books  0.250000  0.062500  0.062500  0.000000   \n",
       "\n",
       "    POS_DET  POS_INTJ  ...   RE  ASF       ASM    OM  RCI  DMC   OR       QAS  \\\n",
       "0  0.151515       0.0  ...  0.0  0.0  0.030303  0.00  0.0  0.0  0.0  0.121212   \n",
       "1  0.200000       0.0  ...  0.0  0.0  0.000000  0.04  0.0  0.0  0.0  0.160000   \n",
       "2  0.222222       0.0  ...  0.0  0.0  0.000000  0.00  0.0  0.0  0.0  0.111111   \n",
       "3  0.142857       0.0  ...  0.0  0.0  0.000000  0.00  0.0  0.0  0.0  0.095238   \n",
       "4  0.187500       0.0  ...  0.0  0.0  0.062500  0.00  0.0  0.0  0.0  0.125000   \n",
       "\n",
       "    PA        PR  \n",
       "0  0.0  0.000000  \n",
       "1  0.0  0.040000  \n",
       "2  0.0  0.111111  \n",
       "3  0.0  0.000000  \n",
       "4  0.0  0.000000  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display(train_df.sample(5, random_state=42))\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64411b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteo de IDs únicos por modelo:\n",
      "model\n",
      "chatgpt          52\n",
      "cohere           52\n",
      "cohere-chat      55\n",
      "gpt2            116\n",
      "gpt3             59\n",
      "gpt4             64\n",
      "human            26\n",
      "llama-chat      105\n",
      "mistral         118\n",
      "mistral-chat    127\n",
      "mpt             120\n",
      "mpt-chat        106\n",
      "Name: id, dtype: int64\n",
      "Total IDs únicos: 1000\n"
     ]
    }
   ],
   "source": [
    "# Contar ids únicos por modelo\n",
    "unique_ids_per_model = train_df.groupby('model')['id'].nunique()\n",
    "print(\"Conteo de IDs únicos por modelo:\")\n",
    "print(unique_ids_per_model)\n",
    "print(\"Total IDs únicos:\", train_df['id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c7efda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame final a un archivo CSV\n",
    "pdtrainDF = pd.DataFrame(train_df)\n",
    "pdtrainDF.to_csv('train_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
