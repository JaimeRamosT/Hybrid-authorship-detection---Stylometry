{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ba2cbfd",
   "metadata": {},
   "source": [
    "# Desarrollo de DF único - Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33e0364",
   "metadata": {},
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2636f4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stylo_metrix as sm\n",
    "import pandas as pd\n",
    "from raid import run_detection, run_evaluation\n",
    "from raid.utils import load_data\n",
    "\n",
    "from processer import split_text_into_sentences\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95d17c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the RAID dataset without adversarial attacks\n",
    "or_train_noadv_df = load_data(split=\"train\", include_adversarial=False)\n",
    "# test_noadv_df = load_data(split=\"test\", include_adversarial=False)\n",
    "# extra_noadv_df = load_data(split=\"extra\", include_adversarial=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "206c9e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>prompt</th>\n",
       "      <th>generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e5e058ce-be2b-459d-af36-32532aaba5ff</td>\n",
       "      <td>human</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The recent advancements in artificial intellig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f95b107b-d176-4af5-90f7-4d0bb20caf93</td>\n",
       "      <td>human</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>EdgeFlow: Achieving Practical Interactive Segm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High-quality training data play a key role in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>856d8972-9e3d-4544-babc-0fe16f21e04d</td>\n",
       "      <td>human</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Semi-supervised Contrastive Learning for Label...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The success of deep learning methods in medica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fbc8a5ea-90fa-47b8-8fa7-73dd954f1524</td>\n",
       "      <td>human</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Combo Loss: Handling Input and Output Imbalanc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Simultaneous segmentation of multiple organs f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72c41b8d-0069-4886-b734-a4000ffca286</td>\n",
       "      <td>human</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Attention-Based 3D Seismic Fault Segmentation ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Detection faults in seismic data is a crucial ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>72fe360b-cce6-4daf-b66a-1d778f5964f8</td>\n",
       "      <td>human</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Segmenter: Transformer for Semantic Segmentation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Image segmentation is often ambiguous at the l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>df594cf4-9a0c-4488-bcb3-68f41e2d5a16</td>\n",
       "      <td>human</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Mining Contextual Information Beyond Image for...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This paper studies the context aggregation pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  model     domain  \\\n",
       "0  e5e058ce-be2b-459d-af36-32532aaba5ff  human  abstracts   \n",
       "1  f95b107b-d176-4af5-90f7-4d0bb20caf93  human  abstracts   \n",
       "2  856d8972-9e3d-4544-babc-0fe16f21e04d  human  abstracts   \n",
       "3  fbc8a5ea-90fa-47b8-8fa7-73dd954f1524  human  abstracts   \n",
       "4  72c41b8d-0069-4886-b734-a4000ffca286  human  abstracts   \n",
       "5  72fe360b-cce6-4daf-b66a-1d778f5964f8  human  abstracts   \n",
       "6  df594cf4-9a0c-4488-bcb3-68f41e2d5a16  human  abstracts   \n",
       "\n",
       "                                               title prompt  \\\n",
       "0  FUTURE-AI: Guiding Principles and Consensus Re...    NaN   \n",
       "1  EdgeFlow: Achieving Practical Interactive Segm...    NaN   \n",
       "2  Semi-supervised Contrastive Learning for Label...    NaN   \n",
       "3  Combo Loss: Handling Input and Output Imbalanc...    NaN   \n",
       "4  Attention-Based 3D Seismic Fault Segmentation ...    NaN   \n",
       "5   Segmenter: Transformer for Semantic Segmentation    NaN   \n",
       "6  Mining Contextual Information Beyond Image for...    NaN   \n",
       "\n",
       "                                          generation  \n",
       "0  The recent advancements in artificial intellig...  \n",
       "1  High-quality training data play a key role in ...  \n",
       "2  The success of deep learning methods in medica...  \n",
       "3  Simultaneous segmentation of multiple organs f...  \n",
       "4  Detection faults in seismic data is a crucial ...  \n",
       "5  Image segmentation is often ambiguous at the l...  \n",
       "6  This paper studies the context aggregation pro...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "intCols = ['id','model', 'domain', 'title', 'prompt', 'generation']\n",
    "# print(\"Visualizar columnas específicas:\")\n",
    "# train_noadv_df = or_train_noadv_df[or_train_noadv_df['model'] != 'human']\n",
    "\n",
    "# Copia del dataframe con columnas específicas\n",
    "train_noadv_df = or_train_noadv_df.copy()\n",
    "train_noadv_df = train_noadv_df[intCols]\n",
    "\n",
    "display(train_noadv_df.head(7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f0d8cc",
   "metadata": {},
   "source": [
    "## Versión 1 - Fusión original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c393a4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model</th>\n",
       "      <th>domain</th>\n",
       "      <th>generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110956</th>\n",
       "      <td>c4059838-c14e-4b84-b75c-12bc0bd2f34a</td>\n",
       "      <td>cohere</td>\n",
       "      <td>books</td>\n",
       "      <td>The story centers on Charles, the husband of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363000</th>\n",
       "      <td>c5001dc3-5baa-4abf-8a1b-2e0bf6d7c77d</td>\n",
       "      <td>gpt3</td>\n",
       "      <td>reddit</td>\n",
       "      <td>\\n\\nJust wondering where do I start?\\n\\nI've b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172379</th>\n",
       "      <td>42bb8f1e-60ec-428d-800c-e9059a0efdab</td>\n",
       "      <td>gpt3</td>\n",
       "      <td>news</td>\n",
       "      <td>\\n\\nLasers are being used to create an ultra-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200619</th>\n",
       "      <td>6a2721a4-d15e-44a9-9f09-e48e60e17a4d</td>\n",
       "      <td>llama-chat</td>\n",
       "      <td>poetry</td>\n",
       "      <td>With eager hands, we plant the seeds,\\nIn fert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27573</th>\n",
       "      <td>4a64da9c-2df8-4f58-91ee-2f9192cc5667</td>\n",
       "      <td>mistral</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Medical image analysis has experienced an expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242879</th>\n",
       "      <td>16d088eb-1511-4711-b8ff-521f77e03ace</td>\n",
       "      <td>mpt-chat</td>\n",
       "      <td>poetry</td>\n",
       "      <td>In the endless, boundless night,\\nWhere darkne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437690</th>\n",
       "      <td>307c1c28-c58f-4f4d-8294-7a89a972268d</td>\n",
       "      <td>mistral-chat</td>\n",
       "      <td>wiki</td>\n",
       "      <td>Matagarup Refugee Camp is a refugee camp locat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217036</th>\n",
       "      <td>07b7c311-9092-4f22-ac67-7a9dc377a82c</td>\n",
       "      <td>mistral</td>\n",
       "      <td>poetry</td>\n",
       "      <td>&gt; Who is your best friend?\\n&gt; I'll tell you wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456322</th>\n",
       "      <td>11c47e1c-54d5-48e4-9835-95125e0c7b2b</td>\n",
       "      <td>gpt4</td>\n",
       "      <td>wiki</td>\n",
       "      <td>Eldora, Colorado is a small unincorporated com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174334</th>\n",
       "      <td>069a165e-431d-4acd-8f82-f8b15ad244a4</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>news</td>\n",
       "      <td>Legendary filmmaker Spike Lee has shown his su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464635</th>\n",
       "      <td>518d3a92-81dd-4f4b-b4e5-b50ff52663ad</td>\n",
       "      <td>mpt-chat</td>\n",
       "      <td>wiki</td>\n",
       "      <td>Ian Austin is an American politician who has s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247377</th>\n",
       "      <td>977785fe-63c8-491e-8497-09f90549d57f</td>\n",
       "      <td>mpt</td>\n",
       "      <td>poetry</td>\n",
       "      <td>( _Note:_ The word \"Kuan\" (卤) means \"meat brot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105187</th>\n",
       "      <td>86bbaa8b-9ad3-4571-bafa-b57ff469f730</td>\n",
       "      <td>cohere</td>\n",
       "      <td>books</td>\n",
       "      <td>The book tells the story of two families, one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128384</th>\n",
       "      <td>7529aefa-f743-4c2c-b6ef-8ddff692b433</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>news</td>\n",
       "      <td>Google's controversial latest entry into the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104791</th>\n",
       "      <td>d266f8fa-febe-4c96-a3f7-6e2b1da35615</td>\n",
       "      <td>gpt3</td>\n",
       "      <td>books</td>\n",
       "      <td>\\n\\nBlack Sunday is a novel by Thomas Harris, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242653</th>\n",
       "      <td>d40dd382-0aab-40ff-9760-722299206249</td>\n",
       "      <td>mpt-chat</td>\n",
       "      <td>poetry</td>\n",
       "      <td>Shall I waste in despair,\\nWith dreams fading ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401184</th>\n",
       "      <td>6d10869e-4e22-4e0b-9a62-d27d40b5d403</td>\n",
       "      <td>gpt3</td>\n",
       "      <td>reviews</td>\n",
       "      <td>\\n\\n12 Monkeys is a mind-bending, time-traveli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95650</th>\n",
       "      <td>d8d242be-b61d-43b8-a010-89cdba0156b2</td>\n",
       "      <td>mistral</td>\n",
       "      <td>books</td>\n",
       "      <td>The Guilty Mother by Margaret Atwood, as well ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32405</th>\n",
       "      <td>7f0748ec-c96e-4f44-9d9c-a93f67bac35d</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>1. Introduction\\n\\nIn this paper, we explore t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420001</th>\n",
       "      <td>a5e27107-47ab-4a8a-91a3-43767eeb2956</td>\n",
       "      <td>llama-chat</td>\n",
       "      <td>wiki</td>\n",
       "      <td>Axone is a 2020 Indian drama film directed by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173432</th>\n",
       "      <td>28724957-59a9-4680-aa4e-57f518727793</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>news</td>\n",
       "      <td>Former Scotland manager Gordon Strachan has re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44477</th>\n",
       "      <td>cc144919-fea4-4d7e-a849-9fc98d6734d0</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>This paper provides a critical analysis of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104164</th>\n",
       "      <td>ae8a648f-c7e8-4b97-961f-7cb66008f9a0</td>\n",
       "      <td>cohere-chat</td>\n",
       "      <td>books</td>\n",
       "      <td>Sure! Here's a plot summary of an equally comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32089</th>\n",
       "      <td>3bd33d47-3112-41f0-8ace-80aac6225c53</td>\n",
       "      <td>mistral-chat</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>In this study, traveling waves for a bistable ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231307</th>\n",
       "      <td>b4fae87a-96f7-4fa0-ba5d-7b04034e3ff9</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>poetry</td>\n",
       "      <td>In this kingdom of ink and shadows cast,\\nTwo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193158</th>\n",
       "      <td>e0a86252-57a1-49ad-a0b0-d16a9845bba7</td>\n",
       "      <td>human</td>\n",
       "      <td>poetry</td>\n",
       "      <td>I fear the fear i cannot stop,\\nI fear it more...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69732</th>\n",
       "      <td>9b09dc00-6d97-403e-9659-5314d44fdca2</td>\n",
       "      <td>llama-chat</td>\n",
       "      <td>books</td>\n",
       "      <td>In a small town nestled in the rolling hills o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89423</th>\n",
       "      <td>bba03a05-86b5-44d6-af56-fdbe649185a8</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>books</td>\n",
       "      <td>In this story, a man named John Doe is accused...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338640</th>\n",
       "      <td>1379ff30-e6e5-415e-b8f6-8619e4736542</td>\n",
       "      <td>mistral</td>\n",
       "      <td>reddit</td>\n",
       "      <td>\"I'll try and keep it short, but there's a lot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456998</th>\n",
       "      <td>f671f191-e7c9-4797-88a4-f7a818aca42a</td>\n",
       "      <td>cohere-chat</td>\n",
       "      <td>wiki</td>\n",
       "      <td>The Ālī Qāpū (Persian: عالی قاپو, romanized: Ā...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439540</th>\n",
       "      <td>65ff4bda-0699-409a-b2e7-54a087fda9f5</td>\n",
       "      <td>mistral</td>\n",
       "      <td>wiki</td>\n",
       "      <td>&gt; Norbert Lossau (28 February 1959 – 7 October...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47167</th>\n",
       "      <td>d1691e42-af05-4014-a47b-f15ab985c545</td>\n",
       "      <td>gpt3</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>\\n\\nIn this paper we present VoteNet, a deep l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          id         model     domain  \\\n",
       "110956  c4059838-c14e-4b84-b75c-12bc0bd2f34a        cohere      books   \n",
       "363000  c5001dc3-5baa-4abf-8a1b-2e0bf6d7c77d          gpt3     reddit   \n",
       "172379  42bb8f1e-60ec-428d-800c-e9059a0efdab          gpt3       news   \n",
       "200619  6a2721a4-d15e-44a9-9f09-e48e60e17a4d    llama-chat     poetry   \n",
       "27573   4a64da9c-2df8-4f58-91ee-2f9192cc5667       mistral  abstracts   \n",
       "242879  16d088eb-1511-4711-b8ff-521f77e03ace      mpt-chat     poetry   \n",
       "437690  307c1c28-c58f-4f4d-8294-7a89a972268d  mistral-chat       wiki   \n",
       "217036  07b7c311-9092-4f22-ac67-7a9dc377a82c       mistral     poetry   \n",
       "456322  11c47e1c-54d5-48e4-9835-95125e0c7b2b          gpt4       wiki   \n",
       "174334  069a165e-431d-4acd-8f82-f8b15ad244a4       chatgpt       news   \n",
       "464635  518d3a92-81dd-4f4b-b4e5-b50ff52663ad      mpt-chat       wiki   \n",
       "247377  977785fe-63c8-491e-8497-09f90549d57f           mpt     poetry   \n",
       "105187  86bbaa8b-9ad3-4571-bafa-b57ff469f730        cohere      books   \n",
       "128384  7529aefa-f743-4c2c-b6ef-8ddff692b433          gpt2       news   \n",
       "104791  d266f8fa-febe-4c96-a3f7-6e2b1da35615          gpt3      books   \n",
       "242653  d40dd382-0aab-40ff-9760-722299206249      mpt-chat     poetry   \n",
       "401184  6d10869e-4e22-4e0b-9a62-d27d40b5d403          gpt3    reviews   \n",
       "95650   d8d242be-b61d-43b8-a010-89cdba0156b2       mistral      books   \n",
       "32405   7f0748ec-c96e-4f44-9d9c-a93f67bac35d          gpt2  abstracts   \n",
       "420001  a5e27107-47ab-4a8a-91a3-43767eeb2956    llama-chat       wiki   \n",
       "173432  28724957-59a9-4680-aa4e-57f518727793       chatgpt       news   \n",
       "44477   cc144919-fea4-4d7e-a849-9fc98d6734d0       chatgpt  abstracts   \n",
       "104164  ae8a648f-c7e8-4b97-961f-7cb66008f9a0   cohere-chat      books   \n",
       "32089   3bd33d47-3112-41f0-8ace-80aac6225c53  mistral-chat  abstracts   \n",
       "231307  b4fae87a-96f7-4fa0-ba5d-7b04034e3ff9       chatgpt     poetry   \n",
       "193158  e0a86252-57a1-49ad-a0b0-d16a9845bba7         human     poetry   \n",
       "69732   9b09dc00-6d97-403e-9659-5314d44fdca2    llama-chat      books   \n",
       "89423   bba03a05-86b5-44d6-af56-fdbe649185a8          gpt2      books   \n",
       "338640  1379ff30-e6e5-415e-b8f6-8619e4736542       mistral     reddit   \n",
       "456998  f671f191-e7c9-4797-88a4-f7a818aca42a   cohere-chat       wiki   \n",
       "439540  65ff4bda-0699-409a-b2e7-54a087fda9f5       mistral       wiki   \n",
       "47167   d1691e42-af05-4014-a47b-f15ab985c545          gpt3  abstracts   \n",
       "\n",
       "                                               generation  \n",
       "110956   The story centers on Charles, the husband of ...  \n",
       "363000  \\n\\nJust wondering where do I start?\\n\\nI've b...  \n",
       "172379  \\n\\nLasers are being used to create an ultra-f...  \n",
       "200619  With eager hands, we plant the seeds,\\nIn fert...  \n",
       "27573   Medical image analysis has experienced an expl...  \n",
       "242879  In the endless, boundless night,\\nWhere darkne...  \n",
       "437690  Matagarup Refugee Camp is a refugee camp locat...  \n",
       "217036  > Who is your best friend?\\n> I'll tell you wh...  \n",
       "456322  Eldora, Colorado is a small unincorporated com...  \n",
       "174334  Legendary filmmaker Spike Lee has shown his su...  \n",
       "464635  Ian Austin is an American politician who has s...  \n",
       "247377  ( _Note:_ The word \"Kuan\" (卤) means \"meat brot...  \n",
       "105187   The book tells the story of two families, one...  \n",
       "128384  Google's controversial latest entry into the f...  \n",
       "104791  \\n\\nBlack Sunday is a novel by Thomas Harris, ...  \n",
       "242653  Shall I waste in despair,\\nWith dreams fading ...  \n",
       "401184  \\n\\n12 Monkeys is a mind-bending, time-traveli...  \n",
       "95650   The Guilty Mother by Margaret Atwood, as well ...  \n",
       "32405   1. Introduction\\n\\nIn this paper, we explore t...  \n",
       "420001  Axone is a 2020 Indian drama film directed by ...  \n",
       "173432  Former Scotland manager Gordon Strachan has re...  \n",
       "44477   This paper provides a critical analysis of the...  \n",
       "104164  Sure! Here's a plot summary of an equally comp...  \n",
       "32089   In this study, traveling waves for a bistable ...  \n",
       "231307  In this kingdom of ink and shadows cast,\\nTwo ...  \n",
       "193158  I fear the fear i cannot stop,\\nI fear it more...  \n",
       "69732   In a small town nestled in the rolling hills o...  \n",
       "89423   In this story, a man named John Doe is accused...  \n",
       "338640  \"I'll try and keep it short, but there's a lot...  \n",
       "456998  The Ālī Qāpū (Persian: عالی قاپو, romanized: Ā...  \n",
       "439540  > Norbert Lossau (28 February 1959 – 7 October...  \n",
       "47167   \\n\\nIn this paper we present VoteNet, a deep l...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get sample dataframe 'generation'\n",
    "\n",
    "filtered_by_domain = train_noadv_df[\n",
    "    (train_noadv_df['domain'] != 'recipes')\n",
    "    ]\n",
    "generation_sample = filtered_by_domain[['id', 'model', 'domain', 'generation']].sample(n=32, random_state=3)\n",
    "\n",
    "display(generation_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "701f0257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_dataset(df_original, sample_size=None):\n",
    "    \"\"\"\n",
    "    Extrae features estilométricos a nivel de oración.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame con estructura: id_original, model, domain, sentence_num, text, features...\n",
    "    \"\"\"\n",
    "    if sample_size:\n",
    "        df_original = df_original.sample(n=sample_size, random_state=42)\n",
    "    \n",
    "    # Inicializar StyloMetrix (sin guardar archivos)\n",
    "    stylo = sm.StyloMetrix('en', debug=False)  # debug=False para evitar archivos\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for idx, row in df_original.iterrows():\n",
    "        # Dividir en oraciones (en memoria)\n",
    "        sentences = split_text_into_sentences(row['generation'])\n",
    "        \n",
    "        # Extraer features para todas las oraciones del documento\n",
    "        features_df = stylo.transform(sentences)\n",
    "        \n",
    "        # Agregar metadatos del documento original\n",
    "        features_df.insert(0, 'id_original', row['id'])\n",
    "        features_df.insert(1, 'model', row['model'])\n",
    "        features_df.insert(2, 'domain', row['domain'])\n",
    "        features_df.insert(3, 'sentence_num', range(len(sentences)))\n",
    "        # La columna 'text' ya existe en features_df (viene de stylo.transform)\n",
    "        \n",
    "        all_results.append(features_df)\n",
    "    \n",
    "    # Concatenar todos los resultados\n",
    "    final_df = pd.concat(all_results, ignore_index=True)\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3c9c4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\spacy\\util.py:910: UserWarning: [W095] Model 'en_core_web_trf' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.2). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/23 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 23/23 [00:02<00:00,  8.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 19/19 [00:02<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 10/10 [00:01<00:00,  9.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 4/4 [00:00<00:00,  8.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 12/12 [00:01<00:00, 11.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 24/24 [00:03<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 14/14 [00:01<00:00,  7.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 9/9 [00:00<00:00, 11.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 18/18 [00:02<00:00,  8.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 11/11 [00:03<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 6/6 [00:01<00:00,  5.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 17/17 [00:02<00:00,  7.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 13/13 [00:01<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 18/18 [00:02<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 14/14 [00:02<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 9/9 [00:01<00:00,  7.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 18/18 [00:02<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 12/12 [00:01<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 19/19 [00:02<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 21/21 [00:02<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 8/8 [00:01<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 9/9 [00:01<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Total de oraciones: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]c:\\Users\\HP\\Desktop\\tesisI\\tests\\ml_algo\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "100%|██████████| 4/4 [00:00<00:00,  7.06it/s]\n"
     ]
    }
   ],
   "source": [
    "features_df = extract_features_from_dataset(generation_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fc130df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (352, 201)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_original</th>\n",
       "      <th>model</th>\n",
       "      <th>domain</th>\n",
       "      <th>sentence_num</th>\n",
       "      <th>text</th>\n",
       "      <th>POS_VERB</th>\n",
       "      <th>POS_NOUN</th>\n",
       "      <th>POS_ADJ</th>\n",
       "      <th>POS_ADV</th>\n",
       "      <th>POS_DET</th>\n",
       "      <th>...</th>\n",
       "      <th>RE</th>\n",
       "      <th>ASF</th>\n",
       "      <th>ASM</th>\n",
       "      <th>OM</th>\n",
       "      <th>RCI</th>\n",
       "      <th>DMC</th>\n",
       "      <th>OR</th>\n",
       "      <th>QAS</th>\n",
       "      <th>PA</th>\n",
       "      <th>PR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c4059838-c14e-4b84-b75c-12bc0bd2f34a</td>\n",
       "      <td>cohere</td>\n",
       "      <td>books</td>\n",
       "      <td>0</td>\n",
       "      <td>The story centers on Charles, the husband of A...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c4059838-c14e-4b84-b75c-12bc0bd2f34a</td>\n",
       "      <td>cohere</td>\n",
       "      <td>books</td>\n",
       "      <td>1</td>\n",
       "      <td>He insists that she stay in the chateau while ...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c4059838-c14e-4b84-b75c-12bc0bd2f34a</td>\n",
       "      <td>cohere</td>\n",
       "      <td>books</td>\n",
       "      <td>2</td>\n",
       "      <td>Charles abruptly ends his trip and returns hom...</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c4059838-c14e-4b84-b75c-12bc0bd2f34a</td>\n",
       "      <td>cohere</td>\n",
       "      <td>books</td>\n",
       "      <td>3</td>\n",
       "      <td>He announces that he has sold the estate, and ...</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c4059838-c14e-4b84-b75c-12bc0bd2f34a</td>\n",
       "      <td>cohere</td>\n",
       "      <td>books</td>\n",
       "      <td>4</td>\n",
       "      <td>Then he hands Alice a key he says he found on ...</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id_original   model domain  sentence_num  \\\n",
       "0  c4059838-c14e-4b84-b75c-12bc0bd2f34a  cohere  books             0   \n",
       "1  c4059838-c14e-4b84-b75c-12bc0bd2f34a  cohere  books             1   \n",
       "2  c4059838-c14e-4b84-b75c-12bc0bd2f34a  cohere  books             2   \n",
       "3  c4059838-c14e-4b84-b75c-12bc0bd2f34a  cohere  books             3   \n",
       "4  c4059838-c14e-4b84-b75c-12bc0bd2f34a  cohere  books             4   \n",
       "\n",
       "                                                text  POS_VERB  POS_NOUN  \\\n",
       "0  The story centers on Charles, the husband of A...  0.200000  0.200000   \n",
       "1  He insists that she stay in the chateau while ...  0.200000  0.133333   \n",
       "2  Charles abruptly ends his trip and returns hom...  0.300000  0.100000   \n",
       "3  He announces that he has sold the estate, and ...  0.375000  0.062500   \n",
       "4  Then he hands Alice a key he says he found on ...  0.235294  0.176471   \n",
       "\n",
       "    POS_ADJ   POS_ADV   POS_DET  ...   RE  ASF  ASM   OM  RCI  DMC   OR  \\\n",
       "0  0.066667  0.000000  0.133333  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.000000  0.000000  0.066667  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.000000  0.200000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.000000  0.062500  0.062500  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.000000  0.058824  0.176471  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "        QAS   PA   PR  \n",
       "0  0.200000  0.0  0.0  \n",
       "1  0.133333  0.0  0.0  \n",
       "2  0.000000  0.0  0.0  \n",
       "3  0.062500  0.0  0.0  \n",
       "4  0.117647  0.0  0.0  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Uso:\n",
    "print(f\"Shape: {features_df.shape}\")\n",
    "display(features_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7538dd9",
   "metadata": {},
   "source": [
    "## Versión 2 - Tags codificados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8c06b4",
   "metadata": {},
   "source": [
    "### Codificación de etiquetas 'model' y 'domain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a825060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información del dataset original:\n",
      "Forma del dataset: (467985, 11)\n",
      "Columnas: ['id', 'adv_source_id', 'source_id', 'model', 'decoding', 'repetition_penalty', 'attack', 'domain', 'title', 'prompt', 'generation']\n",
      "Modelos unicos: ['human' 'llama-chat' 'mpt' 'mpt-chat' 'gpt2' 'mistral' 'mistral-chat'\n",
      " 'gpt3' 'cohere' 'chatgpt' 'gpt4' 'cohere-chat']\n",
      "Dominios unicos: ['abstracts' 'books' 'news' 'poetry' 'recipes' 'reddit' 'reviews' 'wiki']\n"
     ]
    }
   ],
   "source": [
    "print(\"Información del dataset original:\")\n",
    "print(f\"Forma del dataset: {or_train_noadv_df.shape}\")\n",
    "print(f\"Columnas: {list(or_train_noadv_df.columns)}\")\n",
    "print(f\"Modelos unicos: {or_train_noadv_df['model'].unique()}\")\n",
    "print(f\"Dominios unicos: {or_train_noadv_df['domain'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20ace907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información del dataset generado:\n",
      "Forma del dataset: (352, 201)\n",
      "Columnas: ['id_original', 'model', 'domain', 'sentence_num', 'text', 'POS_VERB', 'POS_NOUN', 'POS_ADJ', 'POS_ADV', 'POS_DET', 'POS_INTJ', 'POS_CONJ', 'POS_PART', 'POS_NUM', 'POS_PREP', 'POS_PRO', 'L_REF', 'L_HASHTAG', 'L_MENTION', 'L_RT', 'L_LINKS', 'L_CONT_A', 'L_FUNC_A', 'L_CONT_T', 'L_FUNC_T', 'L_PLURAL_NOUNS', 'L_SINGULAR_NOUNS', 'L_PROPER_NAME', 'L_PERSONAL_NAME', 'L_NOUN_PHRASES', 'L_PUNCT', 'L_PUNCT_DOT', 'L_PUNCT_COM', 'L_PUNCT_SEMC', 'L_PUNCT_COL', 'L_PUNCT_DASH', 'L_POSSESSIVES', 'L_ADJ_POSITIVE', 'L_ADJ_COMPARATIVE', 'L_ADJ_SUPERLATIVE', 'L_ADV_POSITIVE', 'L_ADV_COMPARATIVE', 'L_ADV_SUPERLATIVE', 'PS_CONTRADICTION', 'PS_AGREEMENT', 'PS_EXAMPLES', 'PS_CONSEQUENCE', 'PS_CAUSE', 'PS_LOCATION', 'PS_TIME', 'PS_CONDITION', 'PS_MANNER', 'SY_QUESTION', 'SY_NARRATIVE', 'SY_NEGATIVE_QUESTIONS', 'SY_SPECIAL_QUESTIONS', 'SY_TAG_QUESTIONS', 'SY_GENERAL_QUESTIONS', 'SY_EXCLAMATION', 'SY_IMPERATIVE', 'SY_SUBORD_SENT', 'SY_SUBORD_SENT_PUNCT', 'SY_COORD_SENT', 'SY_COORD_SENT_PUNCT', 'SY_SIMPLE_SENT', 'SY_INVERSE_PATTERNS', 'SY_SIMILE', 'SY_FRONTING', 'SY_IRRITATION', 'SY_INTENSIFIER', 'SY_QUOT', 'VT_PRESENT_SIMPLE', 'VT_PRESENT_PROGRESSIVE', 'VT_PRESENT_PERFECT', 'VT_PRESENT_PERFECT_PROGR', 'VT_PRESENT_SIMPLE_PASSIVE', 'VT_PRESENT_PROGR_PASSIVE', 'VT_PRESENT_PERFECT_PASSIVE', 'VT_PAST_SIMPLE', 'VT_PAST_SIMPLE_BE', 'VT_PAST_PROGR', 'VT_PAST_PERFECT', 'VT_PAST_PERFECT_PROGR', 'VT_PAST_SIMPLE_PASSIVE', 'VT_PAST_POGR_PASSIVE', 'VT_PAST_PERFECT_PASSIVE', 'VT_FUTURE_SIMPLE', 'VT_FUTURE_PROGRESSIVE', 'VT_FUTURE_PERFECT', 'VT_FUTURE_PERFECT_PROGR', 'VT_FUTURE_SIMPLE_PASSIVE', 'VT_FUTURE_PROGR_PASSIVE', 'VT_FUTURE_PERFECT_PASSIVE', 'VT_WOULD', 'VT_WOULD_PASSIVE', 'VT_WOULD_PROGRESSIVE', 'VT_WOULD_PERFECT', 'VT_WOULD_PERFECT_PASSIVE', 'VT_SHOULD', 'VT_SHOULD_PASSIVE', 'VT_SHALL', 'VT_SHALL_PASSIVE', 'VT_SHOULD_PROGRESSIVE', 'VT_SHOULD_PERFECT', 'VT_SHOULD_PERFECT_PASSIVE', 'VT_MUST', 'VT_MUST_PASSIVE', 'VT_MUST_PROGRESSIVE', 'VT_MUST_PERFECT', 'VT_MST_PERFECT_PASSIVE', 'VT_CAN', 'VT_CAN_PASSIVE', 'VT_COULD', 'VT_COULD_PASSIVE', 'VT_CAN_PROGRESSIVE', 'VT_COULD_PROGRESSIVE', 'VT_COULD_PERFECT', 'VT_COULD_PERFECT_PASSIVE', 'VT_MAY', 'VT_MAY_PASSIVE', 'VT_MIGHT', 'VT_MIGHT_PASSIVE', 'VT_MAY_PROGRESSIVE', 'VT_MIGTH_PERFECT', 'VT_MIGHT_PERFECT_PASSIVE', 'VT_MAY_PERFECT_PASSIVE', 'ST_TYPE_TOKEN_RATIO_LEMMAS', 'ST_HERDAN_TTR', 'ST_MASS_TTR', 'ST_SENT_WRDSPERSENT', 'ST_SENT_DIFFERENCE', 'ST_REPETITIONS_WORDS', 'ST_REPETITIONS_SENT', 'ST_SENT_D_VP', 'ST_SENT_D_NP', 'ST_SENT_D_PP', 'ST_SENT_D_ADJP', 'ST_SENT_D_ADVP', 'L_I_PRON', 'L_HE_PRON', 'L_SHE_PRON', 'L_IT_PRON', 'L_YOU_PRON', 'L_WE_PRON', 'L_THEY_PRON', 'L_ME_PRON', 'L_YOU_OBJ_PRON', 'L_HIM_PRON', 'L_HER_OBJECT_PRON', 'L_IT_OBJECT_PRON', 'L_US_PRON', 'L_THEM_PRON', 'L_MY_PRON', 'L_YOUR_PRON', 'L_HIS_PRON', 'L_HER_PRON', 'L_ITS_PRON', 'L_OUR_PRON', 'L_THEIR_PRON', 'L_YOURS_PRON', 'L_THEIRS_PRON', 'L_HERS_PRON', 'L_OURS_PRON', 'L_MYSELF_PRON', 'L_YOURSELF_PRON', 'L_HIMSELF_PRON', 'L_HERSELF_PRON', 'L_ITSELF_PRON', 'L_OURSELVES_PRON', 'L_YOURSELVES_PRON', 'L_THEMSELVES_PRON', 'L_FIRST_PERSON_SING_PRON', 'L_SECOND_PERSON_PRON', 'L_THIRD_PERSON_SING_PRON', 'L_THIRD_PERSON_PLURAL_PRON', 'VF_INFINITIVE', 'G_PASSIVE', 'G_ACTIVE', 'G_PRESENT', 'G_PAST', 'G_FUTURE', 'G_MODALS_SIMPLE', 'G_MODALS_CONT', 'G_MODALS_PERFECT', 'AN', 'DDP', 'SVP', 'CDS', 'DDF', 'IS', 'PS', 'RE', 'ASF', 'ASM', 'OM', 'RCI', 'DMC', 'OR', 'QAS', 'PA', 'PR']\n",
      "Modelos unicos: ['cohere' 'gpt3' 'llama-chat' 'mistral' 'mpt-chat' 'mistral-chat' 'gpt4'\n",
      " 'chatgpt' 'mpt' 'gpt2' 'cohere-chat' 'human']\n",
      "Dominios unicos: ['books' 'reddit' 'news' 'poetry' 'abstracts' 'wiki' 'reviews']\n"
     ]
    }
   ],
   "source": [
    "print(\"Información del dataset generado:\")\n",
    "print(f\"Forma del dataset: {features_df.shape}\")\n",
    "print(f\"Columnas: {list(features_df.columns)}\")\n",
    "print(f\"Modelos unicos: {features_df['model'].unique()}\")\n",
    "print(f\"Dominios unicos: {features_df['domain'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d63f649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificación de etiquetas 'model' y 'domain'\n",
    "id_encoder = LabelEncoder()\n",
    "model_encoder = LabelEncoder()\n",
    "domain_encoder = LabelEncoder()\n",
    "features_df['id_encoded'] = id_encoder.fit_transform(features_df['id_original'])\n",
    "features_df['model_encoded'] = model_encoder.fit_transform(features_df['model'])\n",
    "features_df['domain_encoded'] = domain_encoder.fit_transform(features_df['domain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d7c9480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiquetas codificadas:\n",
      "Modelos:\n",
      "0: chatgpt\n",
      "1: cohere\n",
      "2: cohere-chat\n",
      "3: gpt2\n",
      "4: gpt3\n",
      "5: gpt4\n",
      "6: human\n",
      "7: llama-chat\n",
      "8: mistral\n",
      "9: mistral-chat\n",
      "10: mpt\n",
      "11: mpt-chat\n",
      "\n",
      "Dominios:\n",
      "0: abstracts\n",
      "1: books\n",
      "2: news\n",
      "3: poetry\n",
      "4: reddit\n",
      "5: reviews\n",
      "6: wiki\n"
     ]
    }
   ],
   "source": [
    "print(\"Etiquetas codificadas:\")\n",
    "\n",
    "print(f\"Modelos:\")\n",
    "\n",
    "for i in range(len(model_encoder.classes_)):\n",
    "    print(f\"{i}: {model_encoder.classes_[i]}\")\n",
    "print()\n",
    "\n",
    "print(f\"Dominios:\")\n",
    "for i in range(len(domain_encoder.classes_)):\n",
    "    print(f\"{i}: {domain_encoder.classes_[i]}\")\n",
    "# print(f\"Modelos: {list(model_encoder.classes_)}\")\n",
    "# print(f\"Dominios: {list(domain_encoder.classes_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06f87f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_original</th>\n",
       "      <th>sentence_num</th>\n",
       "      <th>model</th>\n",
       "      <th>domain</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>b4fae87a-96f7-4fa0-ba5d-7b04034e3ff9</td>\n",
       "      <td>15</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>poetry</td>\n",
       "      <td>A political romance, against the odds, An epitome of love's uncompromising gods.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>e0a86252-57a1-49ad-a0b0-d16a9845bba7</td>\n",
       "      <td>9</td>\n",
       "      <td>human</td>\n",
       "      <td>poetry</td>\n",
       "      <td>So fear the fear that i fear, And see that all this mess, Will not be sanitised with truth, When you beg me to confess.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>e0a86252-57a1-49ad-a0b0-d16a9845bba7</td>\n",
       "      <td>3</td>\n",
       "      <td>human</td>\n",
       "      <td>poetry</td>\n",
       "      <td>I cry tears of happiness, To pretend it isnt real, I divulge no information, On what is truely real.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>e0a86252-57a1-49ad-a0b0-d16a9845bba7</td>\n",
       "      <td>1</td>\n",
       "      <td>human</td>\n",
       "      <td>poetry</td>\n",
       "      <td>I close my eyes with acid, And dream while not asleep, To confuse any enemys, Anything i write i eat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>16d088eb-1511-4711-b8ff-521f77e03ace</td>\n",
       "      <td>3</td>\n",
       "      <td>mpt-chat</td>\n",
       "      <td>poetry</td>\n",
       "      <td>So let us embrace this dusky hue, And find solace in its soothing arms, For even in the darkest night, There's a glimmer of hope to be found.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>e0a86252-57a1-49ad-a0b0-d16a9845bba7</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>poetry</td>\n",
       "      <td>I fear the fear i cannot stop, I fear it more and more, And when i grind my teeth with pain, The words come out demure.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>d40dd382-0aab-40ff-9760-722299206249</td>\n",
       "      <td>4</td>\n",
       "      <td>mpt-chat</td>\n",
       "      <td>poetry</td>\n",
       "      <td>So I will not waste in despair, But instead choose to believe, That better days are coming, And my dreams are not dead.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>07b7c311-9092-4f22-ac67-7a9dc377a82c</td>\n",
       "      <td>0</td>\n",
       "      <td>mistral</td>\n",
       "      <td>poetry</td>\n",
       "      <td>&gt; Who is your best friend? &gt; I'll tell you who mine are, &gt; They're my wife and children; &gt; And they don't care! &gt; &gt; If I am sick or sad, &gt; Or if I have to go away, &gt; My wife and children &gt; Are always glad to see me come home that way. &gt; &gt; When I get back from work at night, &gt; There's no one there but them; &gt; But when I leave in the morning, &gt; It seems like half the town has come. &gt; &gt; So, who is your best friend? &gt; Mine are my wife and children; &gt; And they don't care!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>b4fae87a-96f7-4fa0-ba5d-7b04034e3ff9</td>\n",
       "      <td>7</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>poetry</td>\n",
       "      <td>Through heated debates and whispers of disdain, Their love remained, resilient, never waned.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>e0a86252-57a1-49ad-a0b0-d16a9845bba7</td>\n",
       "      <td>8</td>\n",
       "      <td>human</td>\n",
       "      <td>poetry</td>\n",
       "      <td>Seek the maze of happiness, And dont you chase you tail, Dead ends lace every divide, But no one can win or fail.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id_original  sentence_num     model  domain  \\\n",
       "266  b4fae87a-96f7-4fa0-ba5d-7b04034e3ff9            15   chatgpt  poetry   \n",
       "278  e0a86252-57a1-49ad-a0b0-d16a9845bba7             9     human  poetry   \n",
       "272  e0a86252-57a1-49ad-a0b0-d16a9845bba7             3     human  poetry   \n",
       "270  e0a86252-57a1-49ad-a0b0-d16a9845bba7             1     human  poetry   \n",
       "65   16d088eb-1511-4711-b8ff-521f77e03ace             3  mpt-chat  poetry   \n",
       "269  e0a86252-57a1-49ad-a0b0-d16a9845bba7             0     human  poetry   \n",
       "164  d40dd382-0aab-40ff-9760-722299206249             4  mpt-chat  poetry   \n",
       "78   07b7c311-9092-4f22-ac67-7a9dc377a82c             0   mistral  poetry   \n",
       "258  b4fae87a-96f7-4fa0-ba5d-7b04034e3ff9             7   chatgpt  poetry   \n",
       "277  e0a86252-57a1-49ad-a0b0-d16a9845bba7             8     human  poetry   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        text  \n",
       "266                                                                                                                                                                                                                                                                                                                                                                                                         A political romance, against the odds, An epitome of love's uncompromising gods.  \n",
       "278                                                                                                                                                                                                                                                                                                                                                                  So fear the fear that i fear, And see that all this mess, Will not be sanitised with truth, When you beg me to confess.  \n",
       "272                                                                                                                                                                                                                                                                                                                                                                                     I cry tears of happiness, To pretend it isnt real, I divulge no information, On what is truely real.  \n",
       "270                                                                                                                                                                                                                                                                                                                                                                                    I close my eyes with acid, And dream while not asleep, To confuse any enemys, Anything i write i eat.  \n",
       "65                                                                                                                                                                                                                                                                                                                                             So let us embrace this dusky hue, And find solace in its soothing arms, For even in the darkest night, There's a glimmer of hope to be found.  \n",
       "269                                                                                                                                                                                                                                                                                                                                                                  I fear the fear i cannot stop, I fear it more and more, And when i grind my teeth with pain, The words come out demure.  \n",
       "164                                                                                                                                                                                                                                                                                                                                                                  So I will not waste in despair, But instead choose to believe, That better days are coming, And my dreams are not dead.  \n",
       "78   > Who is your best friend? > I'll tell you who mine are, > They're my wife and children; > And they don't care! > > If I am sick or sad, > Or if I have to go away, > My wife and children > Are always glad to see me come home that way. > > When I get back from work at night, > There's no one there but them; > But when I leave in the morning, > It seems like half the town has come. > > So, who is your best friend? > Mine are my wife and children; > And they don't care!  \n",
       "258                                                                                                                                                                                                                                                                                                                                                                                             Through heated debates and whispers of disdain, Their love remained, resilient, never waned.  \n",
       "277                                                                                                                                                                                                                                                                                                                                                                        Seek the maze of happiness, And dont you chase you tail, Dead ends lace every divide, But no one can win or fail.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizar texto de registros aleatorios de dominio poetry\n",
    "pd.set_option('display.max_colwidth', None)  # Sin límite de ancho\n",
    "pd.set_option('display.max_rows', None)      # Sin límite de filas (usar con cuidado)\n",
    "\n",
    "poetry_df = features_df[features_df['domain'] == 'poetry']\n",
    "display(poetry_df[['id_original', 'sentence_num', 'model', 'domain', 'text']].sample(n=10, random_state=11))\n",
    "# 2 7 \n",
    "pd.reset_option('display.max_colwidth')\n",
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999f9507",
   "metadata": {},
   "source": [
    "### Armado de DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "553e30e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar DF final\n",
    "train_df = features_df.copy()\n",
    "\n",
    "trainCols = ['id_encoded', 'sentence_num', 'model_encoded', 'domain_encoded', 'POS_VERB', 'POS_NOUN', 'POS_ADJ', 'POS_ADV', 'POS_DET', 'POS_INTJ', 'POS_CONJ', 'POS_PART', 'POS_NUM', 'POS_PREP', 'POS_PRO', 'L_REF', 'L_HASHTAG', 'L_MENTION', 'L_RT', 'L_LINKS', 'L_CONT_A', 'L_FUNC_A', 'L_CONT_T', 'L_FUNC_T', 'L_PLURAL_NOUNS', 'L_SINGULAR_NOUNS', 'L_PROPER_NAME', 'L_PERSONAL_NAME', 'L_NOUN_PHRASES', 'L_PUNCT', 'L_PUNCT_DOT', 'L_PUNCT_COM', 'L_PUNCT_SEMC', 'L_PUNCT_COL', 'L_PUNCT_DASH', 'L_POSSESSIVES', 'L_ADJ_POSITIVE', 'L_ADJ_COMPARATIVE', 'L_ADJ_SUPERLATIVE', 'L_ADV_POSITIVE', 'L_ADV_COMPARATIVE', 'L_ADV_SUPERLATIVE', 'PS_CONTRADICTION', 'PS_AGREEMENT', 'PS_EXAMPLES', 'PS_CONSEQUENCE', 'PS_CAUSE', 'PS_LOCATION', 'PS_TIME', 'PS_CONDITION', 'PS_MANNER', 'SY_QUESTION', 'SY_NARRATIVE', 'SY_NEGATIVE_QUESTIONS', 'SY_SPECIAL_QUESTIONS', 'SY_TAG_QUESTIONS', 'SY_GENERAL_QUESTIONS', 'SY_EXCLAMATION', 'SY_IMPERATIVE', 'SY_SUBORD_SENT', 'SY_SUBORD_SENT_PUNCT', 'SY_COORD_SENT', 'SY_COORD_SENT_PUNCT', 'SY_SIMPLE_SENT', 'SY_INVERSE_PATTERNS', 'SY_SIMILE', 'SY_FRONTING', 'SY_IRRITATION', 'SY_INTENSIFIER', 'SY_QUOT', 'VT_PRESENT_SIMPLE', 'VT_PRESENT_PROGRESSIVE', 'VT_PRESENT_PERFECT', 'VT_PRESENT_PERFECT_PROGR', 'VT_PRESENT_SIMPLE_PASSIVE', 'VT_PRESENT_PROGR_PASSIVE', 'VT_PRESENT_PERFECT_PASSIVE', 'VT_PAST_SIMPLE', 'VT_PAST_SIMPLE_BE', 'VT_PAST_PROGR', 'VT_PAST_PERFECT', 'VT_PAST_PERFECT_PROGR', 'VT_PAST_SIMPLE_PASSIVE', 'VT_PAST_POGR_PASSIVE', 'VT_PAST_PERFECT_PASSIVE', 'VT_FUTURE_SIMPLE', 'VT_FUTURE_PROGRESSIVE', 'VT_FUTURE_PERFECT', 'VT_FUTURE_PERFECT_PROGR', 'VT_FUTURE_SIMPLE_PASSIVE', 'VT_FUTURE_PROGR_PASSIVE', 'VT_FUTURE_PERFECT_PASSIVE', 'VT_WOULD', 'VT_WOULD_PASSIVE', 'VT_WOULD_PROGRESSIVE', 'VT_WOULD_PERFECT', 'VT_WOULD_PERFECT_PASSIVE', 'VT_SHOULD', 'VT_SHOULD_PASSIVE', 'VT_SHALL', 'VT_SHALL_PASSIVE', 'VT_SHOULD_PROGRESSIVE', 'VT_SHOULD_PERFECT', 'VT_SHOULD_PERFECT_PASSIVE', 'VT_MUST', 'VT_MUST_PASSIVE', 'VT_MUST_PROGRESSIVE', 'VT_MUST_PERFECT', 'VT_MST_PERFECT_PASSIVE', 'VT_CAN', 'VT_CAN_PASSIVE', 'VT_COULD', 'VT_COULD_PASSIVE', 'VT_CAN_PROGRESSIVE', 'VT_COULD_PROGRESSIVE', 'VT_COULD_PERFECT', 'VT_COULD_PERFECT_PASSIVE', 'VT_MAY', 'VT_MAY_PASSIVE', 'VT_MIGHT', 'VT_MIGHT_PASSIVE', 'VT_MAY_PROGRESSIVE', 'VT_MIGTH_PERFECT', 'VT_MIGHT_PERFECT_PASSIVE', 'VT_MAY_PERFECT_PASSIVE', 'ST_TYPE_TOKEN_RATIO_LEMMAS', 'ST_HERDAN_TTR', 'ST_MASS_TTR', 'ST_SENT_WRDSPERSENT', 'ST_SENT_DIFFERENCE', 'ST_REPETITIONS_WORDS', 'ST_REPETITIONS_SENT', 'ST_SENT_D_VP', 'ST_SENT_D_NP', 'ST_SENT_D_PP', 'ST_SENT_D_ADJP', 'ST_SENT_D_ADVP', 'L_I_PRON', 'L_HE_PRON', 'L_SHE_PRON', 'L_IT_PRON', 'L_YOU_PRON', 'L_WE_PRON', 'L_THEY_PRON', 'L_ME_PRON', 'L_YOU_OBJ_PRON', 'L_HIM_PRON', 'L_HER_OBJECT_PRON', 'L_IT_OBJECT_PRON', 'L_US_PRON', 'L_THEM_PRON', 'L_MY_PRON', 'L_YOUR_PRON', 'L_HIS_PRON', 'L_HER_PRON', 'L_ITS_PRON', 'L_OUR_PRON', 'L_THEIR_PRON', 'L_YOURS_PRON', 'L_THEIRS_PRON', 'L_HERS_PRON', 'L_OURS_PRON', 'L_MYSELF_PRON', 'L_YOURSELF_PRON', 'L_HIMSELF_PRON', 'L_HERSELF_PRON', 'L_ITSELF_PRON', 'L_OURSELVES_PRON', 'L_YOURSELVES_PRON', 'L_THEMSELVES_PRON', 'L_FIRST_PERSON_SING_PRON', 'L_SECOND_PERSON_PRON', 'L_THIRD_PERSON_SING_PRON', 'L_THIRD_PERSON_PLURAL_PRON', 'VF_INFINITIVE', 'G_PASSIVE', 'G_ACTIVE', 'G_PRESENT', 'G_PAST', 'G_FUTURE', 'G_MODALS_SIMPLE', 'G_MODALS_CONT', 'G_MODALS_PERFECT', 'AN', 'DDP', 'SVP', 'CDS', 'DDF', 'IS', 'PS', 'RE', 'ASF', 'ASM', 'OM', 'RCI', 'DMC', 'OR', 'QAS', 'PA', 'PR']\n",
    "\n",
    "# trainCols = ['id_original', 'id_encoded', 'sentence_num', 'model_encoded', 'domain_encoded', 'text']\n",
    "\n",
    "train_df = train_df[trainCols]\n",
    "\n",
    "train_df = train_df.rename(columns={\n",
    "    'id_encoded': 'id',\n",
    "    'model_encoded': 'model_label',\n",
    "    'domain_encoded': 'domain_label'\n",
    "})\n",
    "\n",
    "train_df = train_df.sort_values(by=['id', 'sentence_num']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d323249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence_num</th>\n",
       "      <th>model_label</th>\n",
       "      <th>domain_label</th>\n",
       "      <th>POS_VERB</th>\n",
       "      <th>POS_NOUN</th>\n",
       "      <th>POS_ADJ</th>\n",
       "      <th>POS_ADV</th>\n",
       "      <th>POS_DET</th>\n",
       "      <th>POS_INTJ</th>\n",
       "      <th>...</th>\n",
       "      <th>RE</th>\n",
       "      <th>ASF</th>\n",
       "      <th>ASM</th>\n",
       "      <th>OM</th>\n",
       "      <th>RCI</th>\n",
       "      <th>DMC</th>\n",
       "      <th>OR</th>\n",
       "      <th>QAS</th>\n",
       "      <th>PA</th>\n",
       "      <th>PR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.234043</td>\n",
       "      <td>0.234043</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.189655</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.209091</td>\n",
       "      <td>0.127273</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  sentence_num  model_label  domain_label  POS_VERB  POS_NOUN   POS_ADJ  \\\n",
       "0    0             0            0             2  0.153846  0.230769  0.076923   \n",
       "1    0             1            0             2  0.280000  0.320000  0.080000   \n",
       "2    0             2            0             2  0.166667  0.208333  0.166667   \n",
       "3    0             3            0             2  0.166667  0.277778  0.111111   \n",
       "4    0             4            0             2  0.181818  0.303030  0.030303   \n",
       "5    0             5            0             2  0.227273  0.318182  0.090909   \n",
       "6    0             6            0             2  0.200000  0.320000  0.040000   \n",
       "7    0             7            0             2  0.100000  0.300000  0.200000   \n",
       "8    0             8            0             2  0.234043  0.234043  0.042553   \n",
       "9    0             9            0             2  0.086957  0.391304  0.000000   \n",
       "10   0            10            0             2  0.157895  0.315789  0.105263   \n",
       "11   0            11            0             2  0.093750  0.156250  0.062500   \n",
       "12   0            12            0             2  0.189655  0.275862  0.103448   \n",
       "13   0            13            0             2  0.142857  0.285714  0.047619   \n",
       "14   1             0            8             3  0.209091  0.127273  0.045455   \n",
       "15   2             0            5             6  0.157895  0.157895  0.157895   \n",
       "16   2             1            5             6  0.125000  0.187500  0.000000   \n",
       "17   2             2            5             6  0.111111  0.277778  0.055556   \n",
       "18   2             3            5             6  0.080000  0.120000  0.000000   \n",
       "19   2             4            5             6  0.117647  0.117647  0.058824   \n",
       "20   2             5            5             6  0.133333  0.133333  0.066667   \n",
       "21   2             6            5             6  0.200000  0.300000  0.000000   \n",
       "22   2             7            5             6  0.114286  0.228571  0.085714   \n",
       "23   2             8            5             6  0.300000  0.200000  0.000000   \n",
       "24   2             9            5             6  0.200000  0.200000  0.100000   \n",
       "25   2            10            5             6  0.166667  0.200000  0.100000   \n",
       "26   2            11            5             6  0.142857  0.142857  0.142857   \n",
       "27   2            12            5             6  0.150000  0.250000  0.050000   \n",
       "28   2            13            5             6  0.083333  0.583333  0.333333   \n",
       "29   2            14            5             6  0.076923  0.538462  0.076923   \n",
       "\n",
       "     POS_ADV   POS_DET  POS_INTJ  ...        RE  ASF       ASM        OM  RCI  \\\n",
       "0   0.000000  0.076923       0.0  ...  0.000000  0.0  0.000000  0.000000  0.0   \n",
       "1   0.000000  0.080000       0.0  ...  0.000000  0.0  0.000000  0.000000  0.0   \n",
       "2   0.000000  0.083333       0.0  ...  0.000000  0.0  0.083333  0.000000  0.0   \n",
       "3   0.000000  0.166667       0.0  ...  0.000000  0.0  0.000000  0.000000  0.0   \n",
       "4   0.030303  0.121212       0.0  ...  0.000000  0.0  0.000000  0.000000  0.0   \n",
       "5   0.045455  0.045455       0.0  ...  0.000000  0.0  0.000000  0.000000  0.0   \n",
       "6   0.000000  0.120000       0.0  ...  0.000000  0.0  0.000000  0.000000  0.0   \n",
       "7   0.000000  0.100000       0.0  ...  0.000000  0.0  0.000000  0.200000  0.0   \n",
       "8   0.021277  0.148936       0.0  ...  0.000000  0.0  0.021277  0.021277  0.0   \n",
       "9   0.000000  0.086957       0.0  ...  0.000000  0.0  0.000000  0.043478  0.0   \n",
       "10  0.052632  0.157895       0.0  ...  0.000000  0.0  0.000000  0.000000  0.0   \n",
       "11  0.031250  0.031250       0.0  ...  0.000000  0.0  0.000000  0.000000  0.0   \n",
       "12  0.034483  0.137931       0.0  ...  0.000000  0.0  0.000000  0.000000  0.0   \n",
       "13  0.000000  0.095238       0.0  ...  0.000000  0.0  0.000000  0.000000  0.0   \n",
       "14  0.054545  0.045455       0.0  ...  0.000000  0.0  0.018182  0.000000  0.0   \n",
       "15  0.000000  0.052632       0.0  ...  0.000000  0.0  0.000000  0.000000  0.0   \n",
       "16  0.000000  0.187500       0.0  ...  0.000000  0.0  0.000000  0.000000  0.0   \n",
       "17  0.055556  0.055556       0.0  ...  0.000000  0.0  0.000000  0.000000  0.0   \n",
       "18  0.120000  0.080000       0.0  ...  0.000000  0.0  0.000000  0.000000  0.0   \n",
       "19  0.058824  0.235294       0.0  ...  0.000000  0.0  0.000000  0.000000  0.0   \n",
       "20  0.000000  0.133333       0.0  ...  0.000000  0.0  0.000000  0.000000  0.0   \n",
       "21  0.000000  0.200000       0.0  ...  0.000000  0.0  0.000000  0.000000  0.0   \n",
       "22  0.028571  0.142857       0.0  ...  0.000000  0.0  0.000000  0.000000  0.0   \n",
       "23  0.100000  0.200000       0.0  ...  0.000000  0.0  0.000000  0.000000  0.0   \n",
       "24  0.000000  0.200000       0.0  ...  0.000000  0.0  0.000000  0.000000  0.0   \n",
       "25  0.133333  0.133333       0.0  ...  0.000000  0.0  0.000000  0.033333  0.0   \n",
       "26  0.000000  0.142857       0.0  ...  0.000000  0.0  0.000000  0.000000  0.0   \n",
       "27  0.050000  0.050000       0.0  ...  0.000000  0.0  0.000000  0.000000  0.0   \n",
       "28  0.000000  0.083333       0.0  ...  0.000000  0.0  0.000000  0.000000  0.0   \n",
       "29  0.000000  0.153846       0.0  ...  0.076923  0.0  0.000000  0.000000  0.0   \n",
       "\n",
       "         DMC   OR       QAS        PA   PR  \n",
       "0   0.000000  0.0  0.038462  0.000000  0.0  \n",
       "1   0.000000  0.0  0.080000  0.000000  0.0  \n",
       "2   0.000000  0.0  0.041667  0.041667  0.0  \n",
       "3   0.000000  0.0  0.055556  0.000000  0.0  \n",
       "4   0.000000  0.0  0.151515  0.000000  0.0  \n",
       "5   0.000000  0.0  0.000000  0.000000  0.0  \n",
       "6   0.000000  0.0  0.040000  0.000000  0.0  \n",
       "7   0.000000  0.0  0.100000  0.000000  0.0  \n",
       "8   0.000000  0.0  0.085106  0.000000  0.0  \n",
       "9   0.000000  0.0  0.086957  0.000000  0.0  \n",
       "10  0.000000  0.0  0.000000  0.000000  0.0  \n",
       "11  0.000000  0.0  0.031250  0.000000  0.0  \n",
       "12  0.000000  0.0  0.068966  0.000000  0.0  \n",
       "13  0.000000  0.0  0.047619  0.000000  0.0  \n",
       "14  0.000000  0.0  0.018182  0.000000  0.0  \n",
       "15  0.000000  0.0  0.000000  0.000000  0.0  \n",
       "16  0.000000  0.0  0.187500  0.000000  0.0  \n",
       "17  0.000000  0.0  0.000000  0.000000  0.0  \n",
       "18  0.000000  0.0  0.080000  0.000000  0.0  \n",
       "19  0.058824  0.0  0.235294  0.000000  0.0  \n",
       "20  0.000000  0.0  0.200000  0.000000  0.0  \n",
       "21  0.000000  0.0  0.100000  0.000000  0.0  \n",
       "22  0.000000  0.0  0.057143  0.000000  0.0  \n",
       "23  0.000000  0.0  0.200000  0.000000  0.0  \n",
       "24  0.000000  0.0  0.100000  0.000000  0.0  \n",
       "25  0.000000  0.0  0.100000  0.000000  0.0  \n",
       "26  0.000000  0.0  0.142857  0.000000  0.0  \n",
       "27  0.000000  0.0  0.050000  0.000000  0.0  \n",
       "28  0.000000  0.0  0.083333  0.000000  0.0  \n",
       "29  0.000000  0.0  0.153846  0.000000  0.0  \n",
       "\n",
       "[30 rows x 200 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display(train_df.sample(5, random_state=42))\n",
    "display(train_df.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44c7efda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame final a un archivo CSV\n",
    "train_df.to_csv('train_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
